사전 준비 (터미널 명령어)
이 스크립트를 실행하기 위해 필요한 라이브러리입니다. 사내망이라 인터넷이 안 되면 이 패키지들을 pip download로 받아 옮겨야 합니다.

Bash
pip install flask langchain langchain-community langchain-huggingface faiss-cpu sentence-transformers requests
[통합 실행 코드] app.py
이 파일 하나에 웹 서버 + RAG 검색 엔진 + 사내 LLM 연결 + 채팅 UI가 다 들어있습니다. data.txt 파일만 같은 폴더에 두세요.

Python
import os
import requests
import logging
from flask import Flask, request, jsonify, render_template_string
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.language_models.llms import LLM
from typing import Any, List, Optional, Dict

# ========================================================
# 1. [설정] 사내 LLM 및 서버 설정 (여기를 수정하세요)
# ========================================================
COMPANY_API_URL = "http://YOUR_INTERNAL_LLM_IP:PORT/v1/chat/completions" # 사내 LLM 주소
COMPANY_API_KEY = "sk-xxxx"  # 키가 없다면 비워두거나 아무거나 입력
PORT_NUMBER = 10200          # 요청하신 포트 10200
DATA_FILE = "data.txt"       # 엑셀 내용을 복붙한 텍스트 파일명

# 로깅 설정
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ========================================================
# 2. 사내 LLM 연동 모듈 (LangChain 호환 Wrapper)
# ========================================================
class MyCompanyLLM(LLM):
    api_url: str = COMPANY_API_URL
    api_key: str = COMPANY_API_KEY

    @property
    def _llm_type(self) -> str:
        return "company_custom_llm"

    def _call(self, prompt: str, stop: Optional[List[str]] = None, **kwargs: Any) -> str:
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {self.api_key}"
        }
        
        # 사내 LLM이 받는 스펙에 맞춰 Payload 구성 (OpenAI 호환 기준)
        payload = {
            "model": "tgi", # 모델명은 사내 환경에 맞게 수정 필요할 수 있음
            "messages": [
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": prompt}
            ],
            "max_tokens": 1024,
            "temperature": 0.1 # RAG는 사실기반이므로 온도를 낮춤
        }

        try:
            # 사내망 SSL 인증서 에러 무시 (verify=False)
            response = requests.post(self.api_url, json=payload, headers=headers, verify=False, timeout=30)
            response.raise_for_status()
            
            # 응답 파싱 (구조가 다르면 이 부분을 수정해야 함)
            # 보통 response.json()['choices'][0]['message']['content'] 형태
            try:
                data = response.json()
                if "choices" in data:
                    return data['choices'][0]['message']['content']
                elif "generated_text" in data:
                    return data['generated_text']
                else:
                    return str(data)
            except:
                return response.text
                
        except Exception as e:
            logger.error(f"LLM 호출 에러: {e}")
            return f"죄송합니다. LLM 연결에 실패했습니다. ({str(e)})"

    @property
    def _identifying_params(self) -> Dict[str, Any]:
        return {"api_url": self.api_url}

# ========================================================
# 3. RAG 엔진 (데이터 로드 -> 벡터화 -> 검색기)
# ========================================================
def initialize_rag():
    logger.info("RAG 데이터베이스 구축 시작...")
    
    if not os.path.exists(DATA_FILE):
        logger.error(f"'{DATA_FILE}' 파일이 없습니다! 엑셀 내용을 텍스트로 저장해두세요.")
        return None

    # 1. 텍스트 파일 읽기
    with open(DATA_FILE, "r", encoding="utf-8") as f:
        raw_text = f.read()

    # 2. 텍스트 자르기 (엑셀 행 단위 데이터를 보존하기 위해 chunk size 조절)
    # 한 부품의 정보가 잘리지 않도록 넉넉하게 잡고, 겹치는 구간(overlap)을 둠
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=500,
        chunk_overlap=50,
        separators=["\n", "\r\n", " ", ""] # 줄바꿈 우선으로 자름
    )
    splits = text_splitter.create_documents([raw_text])
    logger.info(f"문서 청크 분할 완료: {len(splits)}개")

    # 3. 임베딩 모델 (사내망 로컬 구동용 - 인터넷 필요할 수 있음 최초 1회)
    # 인터넷이 완전히 막힌 경우 'sentence-transformers' 모델 파일을 미리 받아둬야 함
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-MiniLM-L6-v2",
        model_kwargs={'device': 'cpu'}
    )

    # 4. 벡터 저장소(FAISS) 생성
    vectorstore = FAISS.from_documents(documents=splits, embedding=embeddings)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 3}) # 관련 있는 내용 상위 3개 조회
    
    logger.info("RAG 벡터 DB 구축 완료.")
    return retriever

# ========================================================
# 4. Flask 웹 애플리케이션
# ========================================================
app = Flask(__name__)

# RAG 체인 전역 변수
rag_chain = None

# HTML 템플릿 (UI) - 파일 따로 안 만들게 여기에 포함
HTML_TEMPLATE = """
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>부품 스펙 조회 AI</title>
    <style>
        body { font-family: 'Malgun Gothic', sans-serif; background-color: #f4f4f9; display: flex; justify-content: center; height: 100vh; margin: 0; }
        .chat-container { width: 800px; background: white; box-shadow: 0 0 20px rgba(0,0,0,0.1); display: flex; flex-direction: column; height: 90vh; margin-top: 5vh; border-radius: 10px; overflow: hidden; }
        .header { background: #0056b3; color: white; padding: 20px; text-align: center; font-size: 1.2em; font-weight: bold; }
        .messages { flex: 1; padding: 20px; overflow-y: auto; background: #e9ecef; }
        .message { margin-bottom: 15px; display: flex; }
        .message.user { justify-content: flex-end; }
        .message.bot { justify-content: flex-start; }
        .bubble { max-width: 70%; padding: 10px 15px; border-radius: 20px; font-size: 0.95em; line-height: 1.4; white-space: pre-wrap; }
        .user .bubble { background: #0056b3; color: white; border-bottom-right-radius: 0; }
        .bot .bubble { background: white; color: #333; border: 1px solid #ccc; border-bottom-left-radius: 0; }
        .input-area { padding: 20px; background: white; border-top: 1px solid #ddd; display: flex; }
        input[type="text"] { flex: 1; padding: 15px; border: 1px solid #ddd; border-radius: 30px; outline: none; font-size: 1em; }
        button { margin-left: 10px; padding: 0 25px; background: #0056b3; color: white; border: none; border-radius: 30px; cursor: pointer; font-size: 1em; font-weight: bold; }
        button:hover { background: #004494; }
        .loading { font-size: 0.8em; color: #666; text-align: center; margin-top: 10px; display: none;}
    </style>
</head>
<body>
    <div class="chat-container">
        <div class="header">사내 부품 라이브러리 검색 시스템 (RAG)</div>
        <div class="messages" id="messages">
            <div class="message bot"><div class="bubble">안녕하세요. 찾으시는 부품 번호나 스펙을 물어보세요.<br>업로드된 텍스트 데이터를 기반으로 답변해드립니다.</div></div>
        </div>
        <div class="loading" id="loading">AI가 문서를 검색하고 있습니다...</div>
        <div class="input-area">
            <input type="text" id="userInput" placeholder="예: SMD-1002 부품의 허용 전압은 얼마야?" onkeypress="if(event.keyCode==13) sendMessage()">
            <button onclick="sendMessage()">전송</button>
        </div>
    </div>

    <script>
        async function sendMessage() {
            const inputField = document.getElementById('userInput');
            const messageList = document.getElementById('messages');
            const loading = document.getElementById('loading');
            const text = inputField.value.trim();
            
            if (!text) return;

            // 사용자 메시지 추가
            messageList.innerHTML += `<div class="message user"><div class="bubble">${text}</div></div>`;
            inputField.value = '';
            messageList.scrollTop = messageList.scrollHeight;
            loading.style.display = 'block';

            try {
                const response = await fetch('/chat', {
                    method: 'POST',
                    headers: {'Content-Type': 'application/json'},
                    body: JSON.stringify({ message: text })
                });
                const data = await response.json();
                
                // 봇 메시지 추가
                loading.style.display = 'none';
                messageList.innerHTML += `<div class="message bot"><div class="bubble">${data.answer}</div></div>`;
                messageList.scrollTop = messageList.scrollHeight;
            } catch (error) {
                loading.style.display = 'none';
                alert("서버 통신 에러가 발생했습니다.");
            }
        }
    </script>
</body>
</html>
"""

@app.route('/')
def index():
    return render_template_string(HTML_TEMPLATE)

@app.route('/chat', methods=['POST'])
def chat():
    global rag_chain
    user_input = request.json.get('message')
    
    if not rag_chain:
        return jsonify({"answer": "시스템 초기화 중이거나 데이터 파일(data.txt) 문제로 RAG가 준비되지 않았습니다."})

    # RAG 체인 실행
    response = rag_chain.invoke(user_input)
    return jsonify({"answer": response})

# ========================================================
# 5. 메인 실행 블록
# ========================================================
if __name__ == '__main__':
    # SSL 경고 끄기
    import urllib3
    urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

    # 1. 커스텀 LLM 생성
    llm = MyCompanyLLM()

    # 2. RAG 검색기 생성
    retriever = initialize_rag()

    if retriever:
        # 3. 프롬프트 정의 (페르소나 주입)
        # context: 검색된 텍스트 조각들, question: 사용자 질문
        template = """당신은 사내 부품 라이브러리 전문가입니다. 
아래 제공된 [Context]를 바탕으로 질문에 정확하게 답변하세요.
만약 [Context]에 없는 내용이면 "제공된 데이터에 해당 내용이 없습니다"라고 답하세요.
답변은 한국어로 명확하게 작성하세요.

[Context]:
{context}

질문: {question}
답변:"""
        prompt = ChatPromptTemplate.from_template(template)

        # 4. 체인 연결 (검색 -> 프롬프트 -> LLM -> 문자열출력)
        rag_chain = (
            {"context": retriever, "question": RunnablePassthrough()}
            | prompt
            | llm
            | StrOutputParser()
        )
        print(">>> 시스템 준비 완료. 웹 서버를 시작합니다.")
    else:
        print(">>> [경고] 데이터 파일 로드 실패로 RAG 기능 없이 웹 서버만 시작됩니다.")

    # 5. Flask 서버 실행 (포트 10200)
    app.run(host='0.0.0.0', port=PORT_NUMBER, debug=False)
사용법 (이게 안 되면 회사망 문제입니다)
데이터 파일 준비: DRM 해제한 텍스트 파일을 data.txt 라는 이름으로 이 코드(app.py)와 같은 폴더에 넣으세요.

팁: 엑셀 내용을 복사할 때, 부품명과 스펙이 같은 줄에 있도록 복사해야 AI가 잘 찾습니다.

API 주소 수정: 코드 맨 위 COMPANY_API_URL에 님이 쓰시는 내부 LLM 주소 넣으세요.

실행: python app.py

접속: 크롬 켜고 http://localhost:10200 접속.

질문하면 data.txt 뒤져서 내부 모델이 답해줄 겁니다.