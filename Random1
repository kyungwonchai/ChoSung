가지표를 종합적으로 비교하여 가장 좋은 모델을 선정하는 코드입니다. 또한, 결과를 시각화하여 성능을 비교하는 차트를 포함했습니다.

전체 코드: 모델 학습 및 평가
주요 기능:
여러 모델 사용:
LinearRegression
RandomForestRegressor
XGBRegressor
추가 모델을 쉽게 확장 가능
평가지표:
MSE (Mean Squared Error)
RMSE (Root Mean Squared Error)
MAE (Mean Absolute Error)
R² Score
시각화:
막대 차트를 통해 각 모델의 평가지표 비교.
코드
python
코드 복사
# 필요한 라이브러리 임포트
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import joblib

# 데이터 가져오기 함수
def fetch_data_from_db(proc_name):
    """
    MSSQL 저장 프로시저에서 데이터를 가져옵니다.
    :param proc_name: 저장 프로시저 이름
    :return: pandas DataFrame
    """
    import pymssql
    server = "localhost"  # DB 서버 주소
    user = "your_username"  # 사용자 이름
    password = "your_password"  # 비밀번호
    database = "your_database"  # 데이터베이스 이름
    try:
        conn = pymssql.connect(server=server, user=user, password=password, database=database)
        query = f"EXEC {proc_name}"  # 저장 프로시저 실행
        df = pd.read_sql(query, conn)  # pandas DataFrame으로 반환
        return df
    except Exception as e:
        print(f"Error fetching data: {e}")
        return pd.DataFrame()

# 데이터 준비
data = fetch_data_from_db("PRealAandB")  # 저장 프로시저 이름
if data.empty:
    print("No data fetched. Exiting...")
    exit()

# 데이터 전처리
timestamps = data.iloc[:, 0]  # 시간 데이터 (첫 번째 열)
X = data.iloc[:, 2:5].values  # 특징 데이터 (3~5열)
y = data.iloc[:, 1].values    # 타겟 데이터 (2열)

# 학습 및 테스트 데이터 분리
X_train, X_test, y_train, y_test, timestamps_train, timestamps_test = train_test_split(
    X, y, timestamps, test_size=0.2, random_state=42
)

# 사용할 모델 정의
models = {
    "LinearRegression": LinearRegression(),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=100, random_state=42)
}

# 평가지표 저장 딕셔너리
results = {
    "Model": [],
    "MSE": [],
    "RMSE": [],
    "MAE": [],
    "R2_Score": []
}

# 모델 학습 및 평가
print("Training and evaluating models...")
for model_name, model in models.items():
    print(f"Training {model_name}...")
    
    # 모델 학습
    model.fit(X_train, y_train)
    
    # 예측
    y_pred = model.predict(X_test)
    
    # 평가지표 계산
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # 결과 저장
    results["Model"].append(model_name)
    results["MSE"].append(mse)
    results["RMSE"].append(rmse)
    results["MAE"].append(mae)
    results["R2_Score"].append(r2)
    
    print(f"{model_name}: MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}")
    
    # 모델 저장 (가장 좋은 모델일 가능성이 있으므로 모두 저장)
    joblib.dump(model, f"{model_name}.pkl")

# 결과 데이터프레임 생성
results_df = pd.DataFrame(results)

# 최적 모델 선택 (MSE 기준)
best_model_idx = results_df["MSE"].idxmin()
best_model_name = results_df.loc[best_model_idx, "Model"]
print(f"\nBest model: {best_model_name} with MSE={results_df.loc[best_model_idx, 'MSE']:.4f}")

# 시각화: 평가지표 비교
metrics = ["MSE", "RMSE", "MAE", "R2_Score"]
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for i, metric in enumerate(metrics):
    axes[i].bar(results_df["Model"], results_df[metric], color=["blue", "orange", "green"])
    axes[i].set_title(f"Comparison of {metric}")
    axes[i].set_ylabel(metric)
    axes[i].grid(axis="y")

plt.tight_layout()
plt.show()
코드 설명
1. 데이터 준비
fetch_data_from_db: MSSQL에서 데이터를 가져오는 함수.
데이터의 각 열:
첫 번째 열: 시간(timestamps).
2열: 타겟값(y).
3~5열: 특징값(X).
2. 모델 정의
models 딕셔너리:
여러 모델(LinearRegression, RandomForest, XGBoost)을 저장.
필요한 경우 추가 모델을 쉽게 확장 가능.
3. 모델 학습 및 평가
각 모델에 대해 학습, 테스트를 진행하고 평가지표(MSE, RMSE, MAE, R²)를 계산.
각 모델의 성능 결과를 results 딕셔너리에 저장.
4. 최적 모델 선정
MSE가 가장 낮은 모델을 "최적 모델"로 선택.
모든 모델을 각각 joblib.dump로 저장하여 재사용 가능.
5. 시각화
각 평가지표(MSE, RMSE, MAE, R²)를 막대 그래프로 비교.
각 차트는 2x2 그리드로 배치.
결과
평가지표 출력:

모든 모델의 MSE, RMSE, MAE, R² 점수 출력.
최적 모델 선택:

MSE가 가장 낮은 모델 출력.
시각화:

각 모델의 성능(MSE, RMSE, MAE, R²)을 한눈에 비교할 수 있는 막대 차트.
확장 가능성
새로운 모델 추가 가능.