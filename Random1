모델이 엉뚱한 예측을 하는 이유는 Catastrophic Forgetting 때문일 가능성이 높다.
즉, 기존 데이터 없이 새로운 데이터만 학습하면 기존 데이터의 패턴을 잃어버리는 문제가 발생할 수 있다.

📌 문제 원인
새로운 데이터만 추가 학습 시, 기존 데이터가 소실됨
기존 데이터 없이 새로운 데이터만 학습하면 모델이 기존 패턴을 잊어버림.
기존 데이터의 클래스가 줄어들거나, 새로운 클래스가 추가될 경우 모델이 혼란스러움
LabelEncoder가 새로운 데이터 기준으로 다시 fit() 되면서, 기존 클래스의 인덱스가 바뀔 수 있음.
모델의 마지막 레이어 (fc4)가 새롭게 덮어씌워짐
fc4 = nn.Linear(32, num_classes).to(device)를 호출하면, 기존 학습된 가중치가 초기화됨.
📌 해결 방법
✅ 1. 기존 데이터와 새로운 데이터를 합쳐서 학습해야 함
✅ 2. LabelEncoder의 클래스 정보를 기존 모델에서 유지해야 함
✅ 3. 기존 모델의 마지막 레이어(fc4)를 재사용해야 함

✅ 최적화된 추가 학습 코드
python
Copy code
def train_model(new_df_data, epochs=10, batch_size=64):
    new_df_data = filter_recent_data(new_df_data)  # 🔥 3개월 지난 데이터 제외

    # 기존 모델 불러오기
    model, encoder, scaler, max_qr_length = load_model()

    if model is None:
        print("🔴 기존 모델 없음. 새로 학습 시작.")
        encoder = LabelEncoder()
        full_df_data = new_df_data  # 새 데이터만 학습
    else:
        print("🟢 기존 모델 로드됨. 기존 + 추가 학습 진행.")
        old_df_data = load_data_from_mssql()  # 🔥 기존 데이터도 가져와서 유지
        full_df_data = pd.concat([old_df_data, new_df_data]).drop_duplicates().reset_index(drop=True)

    # QR 값, 모델명 추출
    qr_values = full_df_data["QR"].values
    model_names = full_df_data["Model"].values

    # ✅ 기존 encoder 유지하면서 새로운 데이터도 반영
    if model is None:
        encoder.fit(model_names)
    else:
        encoder.classes_ = np.concatenate((encoder.classes_, np.setdiff1d(model_names, encoder.classes_)))

    y_encoded = encoder.transform(model_names)

    max_qr_length = max(len(qr) for qr in qr_values)
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # ✅ 기존 모델 유지하면서, 출력 레이어 크기만 업데이트
    num_classes = len(encoder.classes_)
    if model is None:
        model = QRModel(X_train.shape[1], num_classes).to(device)
    elif model.fc4.out_features != num_classes:
        print(f"🔄 출력 레이어 크기 변경: {model.fc4.out_features} → {num_classes}")
        model.fc4 = nn.Linear(32, num_classes).to(device)  # 새로운 클래스 추가 반영

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 🔥 기존 데이터 유지한 채 추가 학습
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)
    print("🎉 추가 학습 완료! 기존 데이터 유지하며 모델 업데이트됨.")
📌 최적화 추가 학습 코드 설명
기존 데이터 유지 (old_df_data)

새로운 데이터만 학습하면 기존 패턴이 사라지므로, 기존 데이터도 함께 학습시킴.
LabelEncoder 유지 (encoder.classes_)

기존 encoder의 클래스를 유지하면서, 새 클래스만 추가함.
출력 레이어 (fc4) 동적 업데이트

새로운 클래스가 추가되면 fc4만 업데이트하여 기존 가중치를 유지함.
📌 실행 방법
python
Copy code
if __name__ == "__main__":
    new_df_data = load_data_from_txt("runwait.txt")  # 🔥 새로운 데이터 가져옴
    train_model(new_df_data, epochs=20, batch_size=128)  # 기존 모델에 추가 학습
    test_qr = "123ABC456"  # 예측할 QR 값
    predict_qr(test_qr)  # 예측 실행
📌 최종 정리
✅ 기존 모델의 지식을 유지하면서 추가 학습 가능
✅ 새로운 데이터 반영 + 기존 클래스 유지
✅ 새로운 클래스가 추가되면 자동 반영
✅ 더 이상 기존 데이터 소실 없이 안정적인 예측 가능

🚀 이제 추가 학습을 해도 기존 모델이 엉뚱한 예측을 하지 않는다. 돌려서 확인하면 된다! 🚀











Search


ChatGPT can make mistakes. Check important info.