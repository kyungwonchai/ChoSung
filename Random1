import pdfplumber
import re
import numpy as np
import configparser
import os
from typing import List, Dict, Any

# ==============================================================================
# 데이터 구조 및 헬퍼 클래스
# ==============================================================================
class TextElement:
    """PDF에서 추출된 텍스트 객체를 다루기 쉽게 감싼 클래스"""
    def __init__(self, element: Dict[str, Any]):
        self.text = element.get('text', '')
        self.x0, self.top, self.x1, self.bottom = [round(element.get(k, 0), 2) for k in ['x0', 'top', 'x1', 'bottom']]

    def __repr__(self):
        return f"'{self.text}' @ ({self.x0}, {self.top})"

def find_nearest_element(anchor: TextElement, candidates: List[TextElement]) -> TextElement | None:
    """앵커로부터 유클리드 거리가 가장 가까운 요소를 찾습니다."""
    if not candidates:
        return None
    
    anchor_center_x = (anchor.x0 + anchor.x1) / 2
    anchor_center_y = (anchor.top + anchor.bottom) / 2
    
    min_dist = float('inf')
    nearest_element = None
    
    for cand in candidates:
        cand_center_x = (cand.x0 + cand.x1) / 2
        cand_center_y = (cand.top + cand.bottom) / 2
        dist = np.linalg.norm([anchor_center_x - cand_center_x, anchor_center_y - cand_center_y])
        
        if dist < min_dist:
            min_dist = dist
            nearest_element = cand
            
    return nearest_element

def reconstruct_line(words: List[TextElement]) -> str:
    """단어들을 하나의 텍스트 라인으로 재조립합니다."""
    if not words: return ""
    # top 좌표가 비슷한 단어들을 같은 줄로 묶고, x0 좌표 순으로 정렬하여 합칩니다.
    lines = defaultdict(list)
    for word in sorted(words, key=lambda w: (w.top, w.x0)):
        # y좌표 오차 5px 이내를 같은 줄로 간주
        found_line = False
        for y_key in lines.keys():
            if abs(word.top - y_key) < 5:
                lines[y_key].append(word)
                found_line = True
                break
        if not found_line:
            lines[word.top].append(word)
    
    full_text = []
    for y_key in sorted(lines.keys()):
        line_text = " ".join(w.text for w in sorted(lines[y_key], key=lambda w: w.x0))
        full_text.append(line_text)
    
    return " | ".join(full_text) # 여러 줄일 경우 | 문자로 구분

# ==============================================================================
# 메인 분석 함수
# ==============================================================================
def analyze_document_with_learned_spec(pdf_path: str, output_txt_path: str):
    # --- 패턴 정의 ---
    spec_file = 'pageset.ini'
    material_code_pattern = re.compile(r"^\d{4}-\d{6}$")
    top_left_pattern = re.compile(r"^\d{2}[A-Z]?$")
    bottom_right_pattern = re.compile(r"^\d+\s?[xX*]\s?\d+$")

    # --- `pageset.ini` 파일 로드 또는 생성 ---
    config = configparser.ConfigParser()
    master_spec = None

    if os.path.exists(spec_file):
        try:
            config.read(spec_file)
            master_spec = {
                'dist_tl_x': config.getfloat('MasterSpec', 'dist_tl_x'),
                'dist_tl_y': config.getfloat('MasterSpec', 'dist_tl_y'),
                'dist_br_x': config.getfloat('MasterSpec', 'dist_br_x'),
                'dist_br_y': config.getfloat('MasterSpec', 'dist_br_y'),
            }
            print(f"'{spec_file}'에서 학습된 규격을 불러왔습니다.")
        except Exception as e:
            print(f"'{spec_file}' 파일 읽기 오류: {e}. 규격 학습을 다시 시작합니다.")
            master_spec = None
            
    # --- 1차 탐색: `pageset.ini` 파일이 없으면 규격 학습 ---
    if master_spec is None:
        print("1차 탐색: 문서 전체를 스캔하여 '마스터 규격'을 학습합니다...")
        all_distances = []
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                print(f"  - 학습 중... (페이지 {page_num}/{len(pdf.pages)})")
                words = [TextElement(w) for w in page.extract_words()]
                
                material_codes = [w for w in words if material_code_pattern.match(w.text)]
                tl_codes = [w for w in words if top_left_pattern.match(w.text)]
                br_codes = [w for w in words if bottom_right_pattern.match(w.text)]

                for mc in material_codes:
                    nearest_tl = find_nearest_element(mc, tl_codes)
                    nearest_br = find_nearest_element(mc, br_codes)
                    
                    if nearest_tl and nearest_br:
                        dist_tl_x = nearest_tl.x0 - mc.x0
                        dist_tl_y = nearest_tl.top - mc.top
                        dist_br_x = nearest_br.x1 - mc.x1
                        dist_br_y = nearest_br.bottom - mc.bottom
                        all_distances.append([dist_tl_x, dist_tl_y, dist_br_x, dist_br_y])

        if not all_distances:
            raise ValueError("문서 전체에서 유효한 규격 샘플을 찾을 수 없습니다.")

        # 이상치 제거 (IQR 방식)
        distances_arr = np.array(all_distances)
        q1 = np.percentile(distances_arr, 25, axis=0)
        q3 = np.percentile(distances_arr, 75, axis=0)
        iqr = q3 - q1
        lower_bound = q1 - 1.5 * iqr
        upper_bound = q3 + 1.5 * iqr
        
        filtered_distances = distances_arr[
            np.all((distances_arr >= lower_bound) & (distances_arr <= upper_bound), axis=1)
        ]
        
        # 평균 계산하여 마스터 규격 확정
        avg_distances = np.mean(filtered_distances, axis=0)
        master_spec = {
            'dist_tl_x': avg_distances[0], 'dist_tl_y': avg_distances[1],
            'dist_br_x': avg_distances[2], 'dist_br_y': avg_distances[3]
        }
        
        print("학습 완료. 마스터 규격을 `pageset.ini` 파일에 저장합니다.")
        config['MasterSpec'] = {k: str(v) for k, v in master_spec.items()}
        with open(spec_file, 'w') as configfile:
            config.write(configfile)

    # --- 2차 탐색: 학습된 규격을 적용하여 데이터 추출 ---
    print("\n2차 탐색: 학습된 규격을 적용하여 전체 데이터를 추출합니다...")
    final_results = []
    with pdfplumber.open(pdf_path) as pdf:
        for page_num, page in enumerate(pdf.pages, 1):
            words = [TextElement(w) for w in page.extract_words()]
            material_codes = [w for w in words if material_code_pattern.match(w.text)]
            
            for mc in material_codes:
                # 마스터 규격을 적용하여 최종 영역 계산
                box_x0 = mc.x0 + master_spec['dist_tl_x']
                box_top = mc.top + master_spec['dist_tl_y']
                box_x1 = mc.x1 + master_spec['dist_br_x']
                box_bottom = mc.bottom + master_spec['dist_br_y']
                
                # 영역 내 모든 단어 추출
                words_in_box = [w for w in words if w.x0 >= box_x0 and w.x1 <= box_x1 and w.top >= box_top and w.bottom <= box_bottom]
                
                # 한 줄로 재구성하여 결과 저장
                reconstructed_data = reconstruct_line(words_in_box)
                final_results.append((page_num, mc.text, reconstructed_data))
    
    # --- 최종 파일 출력 ---
    with open(output_txt_path, 'w', encoding='utf-8') as f:
        f.write(f"--- 학습된 마스터 규격 (from {spec_file}) ---\n")
        for key, value in master_spec.items():
            f.write(f"- {key}: {value:.2f}px\n")
        f.write("-" * 50 + "\n\n")
        
        f.write("--- 최종 추출 데이터 ---\n")
        for page_num, mc_text, data in final_results:
            f.write(f"페이지: {page_num}, 자재코드: {mc_text}, 정보: [ {data} ]\n")

    print(f"\n모든 분석 완료! 최종 결과가 '{output_txt_path}' 파일에 저장되었습니다.")


# --- 메인 실행 부분 ---
if __name__ == "__main__":
    pdf_file_path = "YOUR_PDF_FILE_PATH.pdf"
    output_file_path = "part_list_final_output.txt"
    analyze_document_with_learned_spec(pdf_file_path, output_file_path)