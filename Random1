API 기반 작업 큐 시스템 구축 가이드 (Ubuntu, Redis, Nginx, Flask, MSSQL)
이 가이드에서는 Ubuntu 환경에서 Redis를 메시지 큐로 활용하고, Flask 기반의 API를 통해 작업을 받아 처리하며, Nginx를 리버스 프록시로 설정하는 전체 과정을 안내합니다. 또한, 처리 중인 작업의 상태를 실시간으로 웹에서 모니터링하고, 작업 내역을 MSSQL 2014 데이터베이스에 연동하여 기록하는 방법을 포함합니다.

1. 시스템 아키텍처
요청이 들어오면 Nginx가 이를 받아 Gunicorn으로 실행되고 있는 Flask 애플리케이션에 전달합니다. Flask API는 요청을 받아 유효성을 검사한 후, Redis Queue(RQ)에 작업을 추가합니다. 별도의 RQ 워커 프로세스가 이 큐를 감시하고 있다가 새로운 작업이 들어오면 가져와서 비동기적으로 처리합니다. 작업 처리 과정 및 결과는 MSSQL 데이터베이스에 기록되며, rq-dashboard를 통해 현재 큐의 상태와 작업 내역을 실시간으로 확인할 수 있습니다.

2. 사전 준비 및 설치
1. 패키지 업데이트 및 기본 라이브러리 설치

Bash

sudo apt-get update
sudo apt-get install -y python3-pip python3-dev build-essential libssl-dev libffi-dev python3-setuptools python3-venv
2. Redis 설치

Bash

sudo apt-get install -y redis-server
설치 후 Redis 서버는 자동으로 실행됩니다. sudo systemctl status redis-server 명령어로 상태를 확인할 수 있습니다.

3. MSSQL ODBC 드라이버 설치

Microsoft의 공식 문서를 참고하여 Ubuntu용 ODBC Driver 17 for SQL Server를 설치합니다.

Bash

# Microsoft GPG 키 등록
curl https://packages.microsoft.com/keys/microsoft.asc | sudo apt-key add -

# Microsoft 제품 리포지토리 등록
curl https://packages.microsoft.com/config/ubuntu/$(lsb_release -rs)/prod.list | sudo tee /etc/apt/sources.list.d/mssql-release.list

sudo apt-get update
sudo ACCEPT_EULA=Y apt-get install -y msodbcsql17
3. Flask 애플리케이션 및 작업 큐 설정
1. 프로젝트 구조

/home/user/remain_monitor
├── venv/
├── app.py
├── tasks.py
└── requirements.txt
2. 가상 환경 설정 및 라이브러리 설치

Bash

cd /home/user/remain_monitor
python3 -m venv venv
source venv/bin/activate

pip install Flask gunicorn flask-rq2 redis rq-dashboard pyodbc
requirements.txt 파일을 생성하고 위 라이브러리들을 명시해두는 것이 좋습니다.

3. Flask 애플리케이션 (app.py)

Python

from flask import Flask, request, jsonify
from flask_rq2 import RQ
import pyodbc

app = Flask(__name__)

# Flask-RQ2 설정
app.config['RQ_REDIS_URL'] = 'redis://localhost:6379/0'
rq = RQ(app)

# MSSQL 연결 정보 (RemainMonitor DB)
MSSQL_SERVER = 'your_server_ip_or_hostname'
MSSQL_DATABASE = 'RemainMonitor'
MSSQL_USERNAME = 'your_username'
MSSQL_PASSWORD = 'your_password'
# ODBC Driver 17 for SQL Server를 사용합니다.
MSSQL_CONNECTION_STRING = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={MSSQL_SERVER};DATABASE={MSSQL_DATABASE};UID={MSSQL_USERNAME};PWD={MSSQL_PASSWORD}'

def get_db_connection():
    """MSSQL 데이터베이스 연결을 생성합니다."""
    try:
        conn = pyodbc.connect(MSSQL_CONNECTION_STRING)
        return conn
    except pyodbc.Error as ex:
        sqlstate = ex.args[0]
        print(f"Database connection error: {sqlstate}")
        return None

# API 엔드포인트: 새로운 작업을 큐에 추가
@app.route('/add-task', methods=['POST'])
def add_task():
    """
    POST 요청을 받아 작업을 Redis 큐에 추가합니다.
    요청 본문 예시: {"data": "처리할 데이터"}
    """
    data = request.get_json()
    if not data or 'data' not in data:
        return jsonify({'error': '데이터가 필요합니다.'}), 400

    # tasks.py의 process_data 함수를 큐에 넣습니다.
    # 두 번째 인자로 전달된 데이터가 process_data 함수의 인자로 사용됩니다.
    job = rq.get_queue().enqueue('tasks.process_data', data['data'])

    return jsonify({'job_id': job.id}), 202

if __name__ == '__main__':
    app.run(debug=True)
4. 작업 함수 (tasks.py)

실제로 비동기적으로 처리될 작업을 정의하는 파일입니다.

Python

import time
import pyodbc
from app import get_db_connection # app.py에서 연결 함수 가져오기

def process_data(data_to_process):
    """
    시간이 오래 걸리는 작업을 시뮬레이션하고,
    처리 시작, 완료 상태를 MSSQL에 기록합니다.
    """
    job_id = rq.get_current_job().id if rq.get_current_job() else 'N/A'
    conn = get_db_connection()
    if not conn:
        print("작업 실패: 데이터베이스에 연결할 수 없습니다.")
        return

    cursor = conn.cursor()

    try:
        # 작업 시작 기록
        # MSSQL 2014는 GETUTCDATE()를 지원합니다.
        cursor.execute("""
            INSERT INTO TaskHistory (JobId, Status, Data, StartTime)
            VALUES (?, ?, ?, GETUTCDATE())
        """, job_id, 'Processing', str(data_to_process))
        conn.commit()

        # 실제 작업 수행 (예: 5초 대기)
        print(f"데이터 처리 시작: {data_to_process}")
        time.sleep(5)
        print("데이터 처리 완료.")

        # 작업 완료 기록
        cursor.execute("""
            UPDATE TaskHistory
            SET Status = ?, EndTime = GETUTCDATE()
            WHERE JobId = ?
        """, 'Completed', job_id)
        conn.commit()

    except Exception as e:
        # 오류 발생 시 기록
        print(f"작업 오류 발생: {e}")
        cursor.execute("""
            UPDATE TaskHistory
            SET Status = ?, ErrorMessage = ?, EndTime = GETUTCDATE()
            WHERE JobId = ?
        """, 'Failed', str(e), job_id)
        conn.commit()
    finally:
        cursor.close()
        conn.close()

    return f"처리 완료: {data_to_process}"
5. MSSQL 테이블 (TaskHistory)

RemainMonitor 데이터베이스에 아래와 같은 테이블을 미리 생성해야 합니다.

SQL

CREATE TABLE TaskHistory (
    Id INT IDENTITY(1,1) PRIMARY KEY,
    JobId NVARCHAR(255) NOT NULL,
    Status NVARCHAR(50),
    Data NVARCHAR(MAX),
    ErrorMessage NVARCHAR(MAX),
    StartTime DATETIME,
    EndTime DATETIME
);
4. RQ 워커 및 대시보드 실행
1. RQ 워커 실행

Flask 애플리케이션과 다른 터미널에서 가상 환경을 활성화한 후, 아래 명령어로 워커를 실행합니다. 워커는 Redis 큐를 감시하며 새로운 작업을 처리합니다.

Bash

source /home/user/remain_monitor/venv/bin/activate
rq worker
2. RQ 대시보드 실행

또 다른 터미널에서 아래 명령어로 실시간 모니터링 웹 대시보드를 실행합니다.

Bash

source /home/user/remain_monitor/venv/bin/activate
rq-dashboard
이제 웹 브라우저에서 http://<서버_IP>:9181로 접속하면 RQ 대시보드를 통해 큐의 상태, 등록된 작업, 성공/실패 여부 등을 실시간으로 확인할 수 있습니다.

5. Gunicorn 및 Nginx 설정 (배포)
1. Gunicorn으로 Flask 앱 실행

Gunicorn은 WSGI 서버로, 프로덕션 환경에서 Flask 애플리케이션을 실행하는 데 사용됩니다.

Bash

# 프로젝트 디렉토리로 이동
cd /home/user/remain_monitor
source venv/bin/activate

# Gunicorn 실행 (백그라운드에서 실행하려면 nohup 등을 사용)
gunicorn --workers 3 --bind unix:remain_monitor.sock -m 007 app:app
--workers 3: 3개의 워커 프로세스를 사용합니다. 서버 사양에 맞게 조절합니다.

--bind unix:remain_monitor.sock: 유닉스 소켓을 통해 Nginx와 통신합니다. IP와 포트(--bind 0.0.0.0:8000)를 사용할 수도 있습니다.

-m 007: 소켓 파일에 대한 권한을 설정하여 Nginx가 접근할 수 있도록 합니다.

2. Nginx 리버스 프록시 설정

Nginx는 외부의 HTTP 요청을 받아 Gunicorn이 실행 중인 내부 소켓으로 전달하는 리버스 프록시 역할을 합니다.

Bash

sudo apt-get install -y nginx
/etc/nginx/sites-available/remain_monitor 파일을 생성하고 아래 내용을 작성합니다.

Nginx

server {
    listen 80;
    server_name your_domain_or_server_ip;

    location / {
        # Gunicorn 소켓으로 요청을 전달
        proxy_pass http://unix:/home/user/remain_monitor/remain_monitor.sock;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
생성한 설정을 활성화하고 Nginx를 재시작합니다.

Bash

# 심볼릭 링크 생성
sudo ln -s /etc/nginx/sites-available/remain_monitor /etc/nginx/sites-enabled

# 기본 설정 파일 링크 제거
sudo unlink /etc/nginx/sites-enabled/default

# Nginx 설정 테스트
sudo nginx -t

# Nginx 재시작