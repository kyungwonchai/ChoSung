상환경에서 nvidia-smi 실행 시 CUDA 12.8이 나오는 문제 해결 방법
가상환경에서 nvidia-smi를 실행할 때 시스템에 설치된 기본 CUDA 버전(12.8)이 표시되는 이유는, nvidia-smi는 CUDA 라이브러리가 아니라 NVIDIA 드라이버를 확인하는 명령어이기 때문입니다.

1. nvidia-smi가 CUDA 12.8을 출력하는 이유
nvidia-smi는 CUDA 드라이버(NVIDIA Driver) 버전을 확인하는 명령어입니다.
이 값은 CUDA 런타임이 아니라 시스템의 NVIDIA 드라이버에서 가져온 정보입니다.
nvidia-smi에서 보이는 CUDA Version은 실제 CUDA 툴킷의 버전이 아닙니다.
✅ 결론: nvidia-smi에서 보이는 버전은 CUDA 실행 환경과 무관하며, 시스템 드라이버의 CUDA 지원 버전을 의미합니다.

🚨 즉, 가상환경에서 nvidia-smi를 실행해도 항상 시스템에 설치된 최신 CUDA 드라이버(12.8)가 보입니다.

2. 가상환경에서 CUDA 12.4를 감지하는 올바른 방법
가상환경에서 실제 CUDA 12.4가 활성화되었는지 확인하려면 다른 방법을 사용해야 합니다.

(1) nvcc --version 실행
sh
코드 복사
nvcc --version
✅ 정상 출력 예시:

arduino
코드 복사
nvcc: NVIDIA (R) Cuda compiler
release 12.4, V12.4.76
❌ 만약 CUDA 12.8이 나온다면?

sh
코드 복사
where nvcc
출력값이 C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.8\bin\nvcc.exe 라면,
CUDA 12.4가 올바르게 등록되지 않은 것입니다. → 아래 해결 방법 실행

(2) 가상환경에서 CUDA 12.4 강제 설정
CUDA 12.4를 가상환경에서 사용하려면 환경 변수를 수동으로 설정해야 합니다.

✅ CMD(관리자 권한)에서 실행
sh
코드 복사
set CUDA_HOME=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4
set PATH=C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v12.4\bin;%PATH%
📌 이 명령어를 실행한 후 다시 nvcc --version을 실행하여 확인하세요.

(3) PyTorch에서 CUDA 12.4 확인
가상환경에서 Python을 실행하고 다음 코드를 입력합니다.

python
코드 복사
import torch
print("CUDA Available:", torch.cuda.is_available())
print("PyTorch CUDA Version:", torch.version.cuda)
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU Found")
✅ 출력 예시 (정상 작동):

yaml
코드 복사
CUDA Available: True
PyTorch CUDA Version: 12.4
GPU Name: NVIDIA GeForce RTX 3090
🚨 만약 CUDA 버전이 여전히 12.8로 나오면?

set CUDA_HOME 명령어를 실행했는지 확인하세요.
환경 변수가 변경되지 않았다면, 터미널을 닫고 다시 실행하세요.
Python에서 torch.version.cuda를 다시 확인하세요.
3. 최종 정리
✅ nvidia-smi는 CUDA 드라이버 버전을 출력하며, 실제 CUDA 툴킷 버전과 무관함.
✅ CUDA 12.4를 감지하려면 nvcc --version을 실행해야 함.
✅ CUDA 12.4를 강제 사용하려면 환경 변수 (set CUDA_HOME)를 설정해야 함.
✅ Python에서 torch.version.cuda로 확인해야 PyTorch에서 올바르게 적용되었는지 알 수 있음.