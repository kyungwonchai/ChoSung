
해결 방법
학습 당시의 최대 QR 길이를 저장
모델 저장 시, 학습 데이터의 최대 QR 길이를 함께 저장합니다.
예측 시 동일한 크기로 패딩(padding) 적용
입력된 QR 값이 학습된 QR 길이보다 짧으면 패딩(0으로 채움)
입력된 QR 값이 학습된 QR 길이보다 길면 잘라서 사용
코드 수정 (오류 해결)
1. 학습 시 최대 QR 길이 저장
python
Copy code
def save_model(model, encoder, scaler, max_qr_length):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_var": scaler.var_,
        "max_qr_length": max_qr_length  # 최대 QR 길이 저장
    }, MODEL_PATH)
2. 모델 불러오기 시 최대 QR 길이 가져오기
python
Copy code
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])
        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.var_ = checkpoint["scaler_var"]

        max_qr_length = checkpoint["max_qr_length"]  # 저장된 QR 길이 로드

        return model, encoder, scaler, max_qr_length
    return None, None, None, None
3. 예측 시 QR 벡터화에서 패딩 추가
python
Copy code
def vectorize_qr(qr_values, max_length):
    vectorized = np.zeros((len(qr_values), max_length), dtype=np.float32)  # max_length만큼 0으로 패딩
    for i, qr in enumerate(qr_values):
        for j, char in enumerate(qr[:max_length]):  # max_length 초과 시 자름
            vectorized[i, j] = ord(char)  # 아스키 코드 변환
    return vectorized
4. 예측 함수 수정 (QR 길이 문제 해결)
python
Copy code
def predict_qr(qr_value):
    model, encoder, scaler, max_qr_length = load_model()
    if model is None:
        print("학습된 모델이 없습니다. 먼저 모델을 학습하세요.")
        return
    
    model.eval()
    X_vectorized = vectorize_qr([qr_value], max_qr_length)  # 학습된 QR 길이에 맞춤
    X_scaled = scaler.transform(X_vectorized)
    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)

    with torch.no_grad():
        outputs = model(X_tensor)
        probabilities = torch.softmax(outputs, dim=1).cpu().numpy().squeeze()

    predicted_label = np.argmax(probabilities)
    predicted_model = encoder.inverse_transform([predicted_label])[0]
    confidence = probabilities[predicted_label] * 100

    print(f"예측된 모델: {predicted_model}, 신뢰도: {confidence:.2f}%")
오류 해결 요약
✅ 모델 학습 시 최대 QR 길이를 저장
✅ 모델 불러올 때 최대 QR 길이를 함께 불러옴
✅ 예측 시 입력된 QR 값이 학습된 QR 길이와 동일하도록 패딩 적용

예측 실행 예제
python
Copy code
test_qr = "123ABC456"  # 입력 QR