import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data_utils
import pandas as pd
import numpy as np
import pymssql
import random
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# ğŸš€ GPU ì„¤ì •
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ“Œ ê¸°ì¡´ ëª¨ë¸ì—ì„œ ìƒ˜í”Œë§í•  ë°ì´í„° ê°œìˆ˜
REPLAY_SIZE = 10000  # ê¸°ì¡´ ë°ì´í„° ì¼ë¶€ ìœ ì§€í•˜ì—¬ ì¶”ê°€ í•™ìŠµ

# ğŸ“Œ ê¸°ì¡´ ëª¨ë¸ì—ì„œ ëœë¤ ìƒ˜í”Œë§ (MSSQL)
def sample_old_data():
    conn = pymssql.connect(server="your_server", user="your_user", password="your_password", database="your_db")
    query = f"""
    SELECT TOP {REPLAY_SIZE} Model, QR
    FROM ModelQRTable
    ORDER BY NEWID()  -- ë¬´ì‘ìœ„ ìƒ˜í”Œë§
    """
    df = pd.read_sql(query, conn)
    conn.close()
    return df

# ğŸ“Œ QR ê°’ì„ ë²¡í„°ë¡œ ë³€í™˜ (ê³ ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”©)
def vectorize_qr(qr_values, max_length):
    vectorized = np.zeros((len(qr_values), max_length), dtype=np.float32)
    for i, qr in enumerate(qr_values):
        for j, char in enumerate(qr[:max_length]):
            vectorized[i, j] = ord(char)
    return vectorized

# ğŸ“Œ ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
class QRModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super(QRModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# ğŸ“Œ ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
MODEL_PATH = "model.pth"
def save_model(model, encoder, scaler, max_qr_length):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_scale": scaler.scale_,
        "max_qr_length": max_qr_length
    }, MODEL_PATH)

# ğŸ“Œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])

        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.eval()

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.scale_ = checkpoint["scaler_scale"]

        max_qr_length = checkpoint["max_qr_length"]

        return model, encoder, scaler, max_qr_length
    return None, None, None, None

# ğŸ“Œ ê¸°ì¡´ ëª¨ë¸ ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ í•™ìŠµ (ê¸°ì¡´ ì¼ë¶€ ìƒ˜í”Œ í¬í•¨)
def train_model(new_df_data, epochs=10, batch_size=64):
    new_df_data = filter_recent_data(new_df_data)  # ğŸ”¥ 3ê°œì›” ì§€ë‚œ ë°ì´í„° ì œì™¸

    # ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model, encoder, scaler, max_qr_length = load_model()

    if model is None:
        print("ğŸ”´ ê¸°ì¡´ ëª¨ë¸ ì—†ìŒ. ìƒˆë¡œ í•™ìŠµ ì‹œì‘.")
        encoder = LabelEncoder()
        max_qr_length = max(len(qr) for qr in new_df_data["QR"].values)
    else:
        print("ğŸŸ¢ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œë¨. ê¸°ì¡´ ê°€ì¤‘ì¹˜ ìœ ì§€í•˜ë©° ì¶”ê°€ í•™ìŠµ ì§„í–‰.")

        # âœ… ê¸°ì¡´ ë°ì´í„° ì¼ë¶€ ìƒ˜í”Œë§í•˜ì—¬ ì¶”ê°€ í•™ìŠµì— í¬í•¨
        old_df_data = sample_old_data()
        new_df_data = pd.concat([old_df_data, new_df_data]).drop_duplicates().reset_index(drop=True)

    # QR ê°’, ëª¨ë¸ëª… ì¶”ì¶œ
    qr_values = new_df_data["QR"].values
    model_names = new_df_data["Model"].values

    # âœ… ê¸°ì¡´ encoder ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ë°ì´í„° ë°˜ì˜
    if model is None:
        encoder.fit(model_names)  # ìƒˆë¡œìš´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ í•™ìŠµ
    else:
        new_classes = np.setdiff1d(model_names, encoder.classes_)
        if len(new_classes) > 0:
            print(f"ğŸ”„ ìƒˆë¡œìš´ í´ë˜ìŠ¤ ì¶”ê°€ë¨: {len(new_classes)} ê°œ")
            encoder.classes_ = np.concatenate((encoder.classes_, new_classes))

    y_encoded = encoder.transform(model_names)

    # âœ… ê¸°ì¡´ ëª¨ë¸ê³¼ ë™ì¼í•œ í¬ê¸°ë¡œ QR ë²¡í„° ë³€í™˜
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    X_scaled = scaler.transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # âœ… ê¸°ì¡´ ëª¨ë¸ ìœ ì§€í•˜ë©´ì„œ, ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ì¶”ê°€ë  ê²½ìš°ë§Œ ì¶œë ¥ ë ˆì´ì–´ ì—…ë°ì´íŠ¸
    num_classes = len(encoder.classes_)
    if model is None:
        model = QRModel(X_train.shape[1], num_classes).to(device)
    elif model.fc4.out_features != num_classes:
        print(f"ğŸ”„ ì¶œë ¥ ë ˆì´ì–´ í¬ê¸° ë³€ê²½: {model.fc4.out_features} â†’ {num_classes}")
        model.fc4 = nn.Linear(32, num_classes).to(device)  # ìƒˆë¡œìš´ í´ë˜ìŠ¤ ì¶”ê°€ ë°˜ì˜

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # ğŸ”¥ ê¸°ì¡´ ê°€ì¤‘ì¹˜ ìœ ì§€í•˜ë©° ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€ í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)