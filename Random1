ë‹¤. QR ê°’ìœ¼ë¡œ ëª¨ë¸ëª…ì„ ì˜ˆì¸¡í•˜ëŠ” ì½”ë“œë¥¼ ë‹¤ì‹œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•´ì„œ ìµœì¢… ì½”ë“œë¥¼ ì¤€ë‹¤.

ğŸ“Œ í•´ê²° ëª©í‘œ
ì…ë ¥ ë°ì´í„°: runwait.txt (ëª¨ë¸ëª…ê³¼ QR ê°’ 2ê°œë§Œ ì‚¬ìš©)
ëª¨ë¸ í•™ìŠµ: QR ê°’ì„ ì…ë ¥í•˜ì—¬ ëª¨ë¸ëª…ì„ ì˜ˆì¸¡í•˜ë„ë¡ í•™ìŠµ
ì˜ˆì¸¡ ë™ì‘: ì‚¬ìš©ìê°€ QRì„ ì…ë ¥í•˜ë©´ ëª¨ë¸ëª…ì„ ì¶œë ¥ (í™•ë¥ ë„ í•¨ê»˜ ì œê³µ)
ëª¨ë¸ ì €ì¥/ë¶ˆëŸ¬ì˜¤ê¸°: í•™ìŠµí•œ ëª¨ë¸ì„ .pth íŒŒì¼ë¡œ ì €ì¥í•˜ê³ , ë‹¤ì‹œ ë¡œë“œí•  ìˆ˜ ìˆë„ë¡ êµ¬ì„±
ë²„ê·¸ í•´ê²°:
ì…ë ¥ ê¸¸ì´ ë¶ˆì¼ì¹˜ ë¬¸ì œ í•´ê²° (QRì„ ë²¡í„°í™”í•  ë•Œ ìµœëŒ€ ê¸¸ì´ ìœ ì§€)
ëª¨ë“ˆ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì¶©ëŒ ì œê±°
QR ê¸¸ì´ê°€ ì§§ì„ ê²½ìš° 0ìœ¼ë¡œ íŒ¨ë”© ì¶”ê°€
ğŸ“Œ ìµœì¢… ì½”ë“œ
python
Copy code
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data_utils
import pandas as pd
import numpy as np
import os
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# ğŸš€ GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU, ì•„ë‹ˆë©´ CPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ğŸ“Œ TXT íŒŒì¼ì—ì„œ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° (ëª¨ë¸ëª… + QR ê°’)
def load_data_from_txt(file_path):
    data = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 2:
                model_name, qr_value = parts[:2]  # ì²« ë²ˆì§¸ëŠ” ëª¨ë¸ëª…, ë‘ ë²ˆì§¸ëŠ” QR ê°’
                data.append((model_name, qr_value))
    return pd.DataFrame(data, columns=["Model", "QR"])

# ğŸ“Œ QR ê°’ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ (ê³ ì •ëœ ê¸¸ì´ë¡œ íŒ¨ë”© í¬í•¨)
def vectorize_qr(qr_values, max_length):
    vectorized = np.zeros((len(qr_values), max_length), dtype=np.float32)
    for i, qr in enumerate(qr_values):
        for j, char in enumerate(qr[:max_length]):  # max_length ì´ˆê³¼ ì‹œ ìë¦„
            vectorized[i, j] = ord(char)  # ë¬¸ì â†’ ì•„ìŠ¤í‚¤ ì½”ë“œ ë³€í™˜
    return vectorized

# ğŸ“Œ ì‹ ê²½ë§ ëª¨ë¸ ì •ì˜
class QRModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super(QRModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, num_classes)  # ëª¨ë¸ ê°œìˆ˜ë§Œí¼ ì¶œë ¥ ë…¸ë“œ ìƒì„±
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.fc4(x)  # ì†Œí”„íŠ¸ë§¥ìŠ¤ ì „ ë‹¨ê³„
        return x

# ğŸ“Œ ëª¨ë¸ ì €ì¥ í•¨ìˆ˜
MODEL_PATH = "model.pth"
def save_model(model, encoder, scaler, max_qr_length):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_var": scaler.var_,
        "max_qr_length": max_qr_length  # QR ìµœëŒ€ ê¸¸ì´ ì €ì¥
    }, MODEL_PATH)

# ğŸ“Œ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])
        
        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.eval()

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.var_ = checkpoint["scaler_var"]

        max_qr_length = checkpoint["max_qr_length"]

        return model, encoder, scaler, max_qr_length
    return None, None, None, None

# ğŸ“Œ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜
def train_model(df_data, epochs=10, batch_size=64):
    qr_values = df_data["QR"].values
    model_names = df_data["Model"].values

    encoder = LabelEncoder()
    y_encoded = encoder.fit_transform(model_names)

    # QR ê°’ì„ ë²¡í„°í™” í›„ ìŠ¤ì¼€ì¼ë§ ì ìš©
    max_qr_length = max(len(qr) for qr in qr_values)  # QR ìµœëŒ€ ê¸¸ì´ ê³„ì‚°
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    # PyTorch ë°ì´í„°ì…‹ & ë°ì´í„°ë¡œë” ìƒì„±
    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # ëª¨ë¸ ì´ˆê¸°í™”
    num_classes = len(encoder.classes_)
    model = QRModel(X_train.shape[1], num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # í•™ìŠµ ë£¨í”„
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)
    print("ğŸ‰ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì €ì¥ë¨.")

# ğŸ“Œ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_qr(qr_value):
    model, encoder, scaler, max_qr_length = load_model()
    if model is None:
        print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš”.")
        return
    
    # QR ê°’ ë²¡í„°í™” (ê¸¸ì´ ë§ì¶”ê¸°)
    X_vectorized = vectorize_qr([qr_value], max_qr_length)
    X_scaled = scaler.transform(X_vectorized)
    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)

    # ì˜ˆì¸¡ ìˆ˜í–‰
    with torch.no_grad():
        outputs = model(X_tensor)
        probabilities = torch.softmax(outputs, dim=1).cpu().numpy().squeeze()

    predicted_label = np.argmax(probabilities)
    predicted_model = encoder.inverse_transform([predicted_label])[0]
    confidence = probabilities[predicted_label] * 100

    print(f"âœ… ì˜ˆì¸¡ëœ ëª¨ë¸: {predicted_model}, ì‹ ë¢°ë„: {confidence:.2f}%")

# ğŸ“Œ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    # TXT íŒŒì¼ ë°ì´í„° ë¡œë“œ í›„ í•™ìŠµ
    df_data = load_data_from_txt("runwait.txt")
    train_model(df_data, epochs=20, batch_size=128)

    # ì˜ˆì¸¡ í…ŒìŠ¤íŠ¸
    test_qr = "123ABC456"  # ì˜ˆì¸¡í•  QR ê°’
    predict_qr(test_qr)
ğŸ“Œ ìµœì¢… ì •ë¦¬
TXT íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë“œ (load_data_from_txt)
QR ê°’ì„ ë²¡í„°í™” (vectorize_qr)
ëª¨ë¸ í•™ìŠµ í›„ ì €ì¥ (train_model)
QR ê°’ ì…ë ¥ ì‹œ ëª¨ë¸ëª… ì˜ˆì¸¡ (predict_qr)
í•™ìŠµëœ ëª¨ë¸ì„ ìë™ìœ¼ë¡œ ë¶ˆëŸ¬ì˜´ (load_model)
ì…ë ¥ QRì´ í•™ìŠµëœ QRê³¼ ê¸¸ì´ê°€ ë‹¤ë¥´ë©´ íŒ¨ë”©ìœ¼ë¡œ ë³´ì •