ëª¨ë¸ì´ ì—‰ëš±í•œ ì˜ˆì¸¡ì„ í•˜ëŠ” ì´ìœ ëŠ” Catastrophic Forgetting ë•Œë¬¸ì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤.
ì¦‰, ê¸°ì¡´ ë°ì´í„° ì—†ì´ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•™ìŠµí•˜ë©´ ê¸°ì¡´ ë°ì´í„°ì˜ íŒ¨í„´ì„ ìƒì–´ë²„ë¦¬ëŠ” ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤.

ğŸ“Œ ë¬¸ì œ ì›ì¸
ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€ í•™ìŠµ ì‹œ, ê¸°ì¡´ ë°ì´í„°ê°€ ì†Œì‹¤ë¨
ê¸°ì¡´ ë°ì´í„° ì—†ì´ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•™ìŠµí•˜ë©´ ëª¨ë¸ì´ ê¸°ì¡´ íŒ¨í„´ì„ ìŠì–´ë²„ë¦¼.
ê¸°ì¡´ ë°ì´í„°ì˜ í´ë˜ìŠ¤ê°€ ì¤„ì–´ë“¤ê±°ë‚˜, ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ì¶”ê°€ë  ê²½ìš° ëª¨ë¸ì´ í˜¼ë€ìŠ¤ëŸ¬ì›€
LabelEncoderê°€ ìƒˆë¡œìš´ ë°ì´í„° ê¸°ì¤€ìœ¼ë¡œ ë‹¤ì‹œ fit() ë˜ë©´ì„œ, ê¸°ì¡´ í´ë˜ìŠ¤ì˜ ì¸ë±ìŠ¤ê°€ ë°”ë€” ìˆ˜ ìˆìŒ.
ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ (fc4)ê°€ ìƒˆë¡­ê²Œ ë®ì–´ì”Œì›Œì§
fc4 = nn.Linear(32, num_classes).to(device)ë¥¼ í˜¸ì¶œí•˜ë©´, ê¸°ì¡´ í•™ìŠµëœ ê°€ì¤‘ì¹˜ê°€ ì´ˆê¸°í™”ë¨.
ğŸ“Œ í•´ê²° ë°©ë²•
âœ… 1. ê¸°ì¡´ ë°ì´í„°ì™€ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ í•©ì³ì„œ í•™ìŠµí•´ì•¼ í•¨
âœ… 2. LabelEncoderì˜ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ê¸°ì¡´ ëª¨ë¸ì—ì„œ ìœ ì§€í•´ì•¼ í•¨
âœ… 3. ê¸°ì¡´ ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´(fc4)ë¥¼ ì¬ì‚¬ìš©í•´ì•¼ í•¨

âœ… ìµœì í™”ëœ ì¶”ê°€ í•™ìŠµ ì½”ë“œ
python
Copy code
def train_model(new_df_data, epochs=10, batch_size=64):
    new_df_data = filter_recent_data(new_df_data)  # ğŸ”¥ 3ê°œì›” ì§€ë‚œ ë°ì´í„° ì œì™¸

    # ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model, encoder, scaler, max_qr_length = load_model()

    if model is None:
        print("ğŸ”´ ê¸°ì¡´ ëª¨ë¸ ì—†ìŒ. ìƒˆë¡œ í•™ìŠµ ì‹œì‘.")
        encoder = LabelEncoder()
        full_df_data = new_df_data  # ìƒˆ ë°ì´í„°ë§Œ í•™ìŠµ
    else:
        print("ğŸŸ¢ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œë¨. ê¸°ì¡´ + ì¶”ê°€ í•™ìŠµ ì§„í–‰.")
        old_df_data = load_data_from_mssql()  # ğŸ”¥ ê¸°ì¡´ ë°ì´í„°ë„ ê°€ì ¸ì™€ì„œ ìœ ì§€
        full_df_data = pd.concat([old_df_data, new_df_data]).drop_duplicates().reset_index(drop=True)

    # QR ê°’, ëª¨ë¸ëª… ì¶”ì¶œ
    qr_values = full_df_data["QR"].values
    model_names = full_df_data["Model"].values

    # âœ… ê¸°ì¡´ encoder ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ë°ì´í„°ë„ ë°˜ì˜
    if model is None:
        encoder.fit(model_names)
    else:
        encoder.classes_ = np.concatenate((encoder.classes_, np.setdiff1d(model_names, encoder.classes_)))

    y_encoded = encoder.transform(model_names)

    max_qr_length = max(len(qr) for qr in qr_values)
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # âœ… ê¸°ì¡´ ëª¨ë¸ ìœ ì§€í•˜ë©´ì„œ, ì¶œë ¥ ë ˆì´ì–´ í¬ê¸°ë§Œ ì—…ë°ì´íŠ¸
    num_classes = len(encoder.classes_)
    if model is None:
        model = QRModel(X_train.shape[1], num_classes).to(device)
    elif model.fc4.out_features != num_classes:
        print(f"ğŸ”„ ì¶œë ¥ ë ˆì´ì–´ í¬ê¸° ë³€ê²½: {model.fc4.out_features} â†’ {num_classes}")
        model.fc4 = nn.Linear(32, num_classes).to(device)  # ìƒˆë¡œìš´ í´ë˜ìŠ¤ ì¶”ê°€ ë°˜ì˜

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # ğŸ”¥ ê¸°ì¡´ ë°ì´í„° ìœ ì§€í•œ ì±„ ì¶”ê°€ í•™ìŠµ
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)
    print("ğŸ‰ ì¶”ê°€ í•™ìŠµ ì™„ë£Œ! ê¸°ì¡´ ë°ì´í„° ìœ ì§€í•˜ë©° ëª¨ë¸ ì—…ë°ì´íŠ¸ë¨.")
ğŸ“Œ ìµœì í™” ì¶”ê°€ í•™ìŠµ ì½”ë“œ ì„¤ëª…
ê¸°ì¡´ ë°ì´í„° ìœ ì§€ (old_df_data)

ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•™ìŠµí•˜ë©´ ê¸°ì¡´ íŒ¨í„´ì´ ì‚¬ë¼ì§€ë¯€ë¡œ, ê¸°ì¡´ ë°ì´í„°ë„ í•¨ê»˜ í•™ìŠµì‹œí‚´.
LabelEncoder ìœ ì§€ (encoder.classes_)

ê¸°ì¡´ encoderì˜ í´ë˜ìŠ¤ë¥¼ ìœ ì§€í•˜ë©´ì„œ, ìƒˆ í´ë˜ìŠ¤ë§Œ ì¶”ê°€í•¨.
ì¶œë ¥ ë ˆì´ì–´ (fc4) ë™ì  ì—…ë°ì´íŠ¸

ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ì¶”ê°€ë˜ë©´ fc4ë§Œ ì—…ë°ì´íŠ¸í•˜ì—¬ ê¸°ì¡´ ê°€ì¤‘ì¹˜ë¥¼ ìœ ì§€í•¨.
ğŸ“Œ ì‹¤í–‰ ë°©ë²•
python
Copy code
if __name__ == "__main__":
    new_df_data = load_data_from_txt("runwait.txt")  # ğŸ”¥ ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜´
    train_model(new_df_data, epochs=20, batch_size=128)  # ê¸°ì¡´ ëª¨ë¸ì— ì¶”ê°€ í•™ìŠµ
    test_qr = "123ABC456"  # ì˜ˆì¸¡í•  QR ê°’
    predict_qr(test_qr)  # ì˜ˆì¸¡ ì‹¤í–‰
ğŸ“Œ ìµœì¢… ì •ë¦¬
âœ… ê¸°ì¡´ ëª¨ë¸ì˜ ì§€ì‹ì„ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ í•™ìŠµ ê°€ëŠ¥
âœ… ìƒˆë¡œìš´ ë°ì´í„° ë°˜ì˜ + ê¸°ì¡´ í´ë˜ìŠ¤ ìœ ì§€
âœ… ìƒˆë¡œìš´ í´ë˜ìŠ¤ê°€ ì¶”ê°€ë˜ë©´ ìë™ ë°˜ì˜
âœ… ë” ì´ìƒ ê¸°ì¡´ ë°ì´í„° ì†Œì‹¤ ì—†ì´ ì•ˆì •ì ì¸ ì˜ˆì¸¡ ê°€ëŠ¥

ğŸš€ ì´ì œ ì¶”ê°€ í•™ìŠµì„ í•´ë„ ê¸°ì¡´ ëª¨ë¸ì´ ì—‰ëš±í•œ ì˜ˆì¸¡ì„ í•˜ì§€ ì•ŠëŠ”ë‹¤. ëŒë ¤ì„œ í™•ì¸í•˜ë©´ ëœë‹¤! ğŸš€











Search


ChatGPT can make mistakes. Check important info.