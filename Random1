import os
import csv
from datetime import datetime

# Log file directory
log_directory = "c:/test"

# Dictionary to store unique SentValue prefixes
unique_prefixes = {}

# List to store the parsed log data for both commandqueue and other logs
log_data = []

# Process commandqueue files
for filename in os.listdir(log_directory):
    if filename.endswith(".txt") and "commandqueue" in filename.lower():
        file_path = os.path.join(log_directory, filename)
        
        # Open and read the file once
        with open(file_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            for line in lines:
                # Split the line by '|'
                parts = line.strip().split('|')
                if len(parts) == 7:  # Only process if all required fields are present
                    # Extract the first 14 characters of SentValue as a prefix
                    prefix = parts[1][:14]
                    unique_prefixes[prefix] = None  # Store as a key for uniqueness
                    
                    # Extract response value based on conditions
                    response_value = parts[2]
                    if "WDD" in prefix:
                        sent_value = parts[1]
                        extracted_value = sent_value[19:] if len(sent_value) >= 20 else ""
                    else:
                        extracted_value = response_value[-7:] if len(response_value) >= 7 else response_value
                    
                    # Remove the last 2 characters from the extracted value
                    extracted_value = extracted_value[:-2] if len(extracted_value) > 2 else ""
                    
                    # Add the row to the log data list
                    log_data.append([parts[0], parts[1], parts[2], parts[3], parts[4], parts[5], parts[6], prefix, extracted_value, "commandqueue"])

# Process other .txt files (non-commandqueue files)
for filename in os.listdir(log_directory):
    if filename.endswith(".txt") and "commandqueue" not in filename.lower():
        file_path = os.path.join(log_directory, filename)
        
        # Open and read the file once, process all lines at once
        with open(file_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            for line in lines:
                # Extract time value enclosed in [] and the remaining part as SentValue
                if '[' in line and ']' in line:
                    start_idx = line.index('[')
                    end_idx = line.index(']', start_idx) + 1
                    time_value = line[start_idx:end_idx]  # Extract the time value with brackets
                    remaining_value = line[end_idx:].strip()  # Remaining part of the line as SentValue
                    
                    # Add a row for non-commandqueue logs, filling other columns as empty
                    log_data.append([time_value, remaining_value, "", "", "", "", "", "", "", "non-commandqueue"])

# Sort the log data by the time value
log_data.sort(key=lambda x: x[0])

# Prepare the output directory
output_directory = "c:/test/csv2"
os.makedirs(output_directory, exist_ok=True)

# Create the output file name with the current timestamp
timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
output_file = os.path.join(output_directory, f"{timestamp}_merged_log_output.csv")

# Save the sorted data to a CSV file
with open(output_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
    csvwriter = csv.writer(csvfile)
    
    # Write column headers
    headers = ["Time", "SentValue", "ResponseValue", "Result", "Result2", "Retry", "Speed", "Prefix", "ExtractedValue", "LogType"]
    csvwriter.writerow(headers)
    
    # Write all the data at once
    for row in log_data:
        # Ensure all values are treated as text
        formatted_row = [f"'{value}" if value else "" for value in row]
        csvwriter.writerow(formatted_row)
