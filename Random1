
📌 해결 방법
저장할 때 .scale_ 대신 .var_ 사용하도록 변경합니다.

📌 수정할 코드
✅ 모델 저장 시 scale_ 대신 var_ 사용
python
Copy code
def save_model(model, encoder, scaler, max_qr_length):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_var": scaler.var_,  # ✅ scale_ 대신 var_ 저장
        "max_qr_length": max_qr_length
    }, MODEL_PATH)
✅ 모델 불러올 때도 var_로 변경
python
Copy code
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])
        
        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.eval()

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.var_ = checkpoint["scaler_var"]  # ✅ scale_ 대신 var_ 사용

        max_qr_length = checkpoint["max_qr_length"]

        return model, encoder, scaler, max_qr_length
    return None, None, None, None
📌 최종 정리
원인: StandardScaler의 .scale_ 속성이 없기 때문
해결: .scale_을 .var_로 변경하면 해결됨
수정한 부분: