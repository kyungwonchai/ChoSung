아래는 여러 머신러닝 모델을 사용해 최적의 모델을 선택하고, 이후 해당 모델로 예측 및 시각화를 수행하는 코드를 Jupyter Notebook에 맞게 분리하여 작성한 내용입니다.

1. 학습 및 최적 모델 생성 코드
DB에서 데이터 불러오기: PandB 데이터를 MSSQL 저장 프로시저에서 불러옵니다.
여러 모델 사용: XGBoost, RandomForest, LinearRegression 등을 사용해 최적의 모델을 선택합니다.
최적 모델 저장: 학습 완료 후 최적의 모델을 저장합니다.
python
코드 복사
# 필요한 라이브러리 설치 및 임포트
!pip install pandas scikit-learn xgboost pymssql matplotlib --quiet

import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
import pymssql
import joblib  # 모델 저장용

# 데이터베이스에서 PandB 데이터를 불러오는 함수
def fetch_data_from_procedure(proc_name):
    """
    MSSQL 저장 프로시저를 호출하여 PandB 데이터를 가져옵니다.
    """
    server = "localhost"  # DB 서버 주소
    user = "your_username"  # 사용자 이름
    password = "your_password"  # 비밀번호
    database = "your_database"  # 데이터베이스 이름

    try:
        conn = pymssql.connect(server=server, user=user, password=password, database=database)
        query = f"EXEC {proc_name}"  # 저장 프로시저 실행
        df = pd.read_sql(query, conn)  # 데이터프레임으로 변환
        return df
    except Exception as e:
        print(f"Error fetching data: {e}")
        return pd.DataFrame()

# PandB 데이터 가져오기
data = fetch_data_from_procedure("GetPandB")  # 저장 프로시저 이름
if data.empty:
    print("No data fetched. Please check your stored procedure.")
    exit()

# 데이터 준비
X = data.iloc[:, :-1].values  # 특징 데이터
y = data.iloc[:, -1].values  # 타겟 데이터

# 사용할 모델 정의
models = {
    "XGBoost": XGBRegressor(random_state=42),
    "RandomForest": RandomForestRegressor(random_state=42),
    "LinearRegression": LinearRegression()
}

# K-Fold 교차 검증
kf = KFold(n_splits=5, shuffle=True, random_state=42)
best_model_name = None
best_model = None
lowest_mse = float("inf")

print("Training models with K-Fold cross-validation...")
for model_name, model in models.items():
    mse_scores = []

    for train_idx, val_idx in kf.split(X):
        X_train, X_val = X[train_idx], X[val_idx]
        y_train, y_val = y[train_idx], y[val_idx]

        # 모델 학습
        model.fit(X_train, y_train)
        
        # 검증
        predictions = model.predict(X_val)
        mse = mean_squared_error(y_val, predictions)
        mse_scores.append(mse)

    # 평균 MSE 계산
    avg_mse = np.mean(mse_scores)
    print(f"{model_name}: Average MSE = {avg_mse:.4f}")

    # 최적 모델 선택
    if avg_mse < lowest_mse:
        lowest_mse = avg_mse
        best_model_name = model_name
        best_model = model

# 최적 모델 출력 및 저장
print(f"Best model: {best_model_name} with MSE = {lowest_mse:.4f}")
joblib.dump(best_model, "best_model.pkl")
print("Best model saved as 'best_model.pkl'")
2. 예측 및 시각화 코드
모델 로드: 저장된 최적 모델을 불러옵니다.
예측 및 시각화: pnowab 데이터를 입력으로 사용해 예측하고, 결과를 시각적으로 보여줍니다.
python
코드 복사
# 필요한 라이브러리 임포트
import joblib
import matplotlib.pyplot as plt

# 저장된 모델 로드
try:
    model = joblib.load("best_model.pkl")
    print("Best model loaded successfully.")
except Exception as e:
    print(f"Error loading model: {e}")
    exit()

# pnowab 데이터
# pnowab는 실제 데이터에 맞게 수정 필요
pnowab = np.array([[1.5, 3.3, 5.5, 7.2]])  # 예제 데이터

# 예측 수행
predicted = model.predict(pnowab).flatten()
print(f"Predicted values: {predicted}")

# 실제값 (예제용)
actual = np.array([1.4, 3.5, 5.7, 7.0])  # 실제값

# 시각화: 예측값 vs 실제값
features = ['ap', 'bp', 'cp', 'dp']

# 예측값 선 연결
plt.figure(figsize=(10, 6))
plt.plot(features, predicted, label='Predicted', linestyle='--', marker='o')

# 실제값 점 표시
plt.scatter(features, actual, color='red', label='Actual', zorder=5)

# 오차 표시
for i, (pred, act) in enumerate(zip(predicted, actual)):
    plt.plot([features[i], features[i]], [pred, act], 'k--', alpha=0.7)

# 레이블 및 제목
plt.title("Prediction vs Actual")
plt.xlabel("Features")
plt.ylabel("Values")
plt.legend()
plt.grid()
plt.show()

# 오차 점수 시각화
errors = np.abs(predicted - actual)  # 오차 계산
error_scores = 100 - (errors / np.max(errors) * 100)  # 100점 만점 기준

plt.figure(figsize=(10, 6))
plt.bar(features, error_scores, color='blue', alpha=0.7)
plt.axhline(100, color='green', linestyle='--', label='Max Score (100)')
plt.title("Error Score (100-point scale)")
plt.xlabel("Features")
plt.ylabel("Score")
plt.legend()
plt.ylim(0, 100)
plt.grid()
plt.show()

# 오차 점수 출력
print(f"Error Scores (100-point scale): {error_scores}")
구성 요약
1. 학습 및 모델 저장
DB에서 PandB 데이터 불러오기: MSSQL 저장 프로시저를 호출하여 데이터 로드.
여러 모델 사용: XGBoost, RandomForest, LinearRegression을 사용해 최적 모델 선정.
K-Fold 교차 검증: 5개의 폴드로 데이터를 나눠 학습 및 검증.
최적 모델 저장: joblib를 사용하여 최적 모델 저장.
2. 예측 및 시각화
모델 불러오기: 저장된 최적 모델(best_model.pkl)을 로드.
예측 수행: pnowab 데이터를 입력하여 예측값 생성.
결과 시각화:
예측 vs 실제값 차트: 선(예측값)과 점(실제값)을 비교.
오차 점수 차트: 100점 만점 기준으로 정확도 점수를 막대 그래프로 표시.
필요 사항
MSSQL 저장 프로시저:

GetPandB를 적절히 구현해야 합니다.
데이터 구조가 정확히 일치해야 합니다.
실제 데이터 입력:
