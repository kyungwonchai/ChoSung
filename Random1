
ğŸ“Œ í•´ê²° ë°©ë²•
ì €ì¥í•  ë•Œ .scale_ ëŒ€ì‹  .var_ ì‚¬ìš©í•˜ë„ë¡ ë³€ê²½í•©ë‹ˆë‹¤.

ğŸ“Œ ìˆ˜ì •í•  ì½”ë“œ
âœ… ëª¨ë¸ ì €ì¥ ì‹œ scale_ ëŒ€ì‹  var_ ì‚¬ìš©
python
Copy code
def save_model(model, encoder, scaler, max_qr_length):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_var": scaler.var_,  # âœ… scale_ ëŒ€ì‹  var_ ì €ì¥
        "max_qr_length": max_qr_length
    }, MODEL_PATH)
âœ… ëª¨ë¸ ë¶ˆëŸ¬ì˜¬ ë•Œë„ var_ë¡œ ë³€ê²½
python
Copy code
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])
        
        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])
        model.eval()

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.var_ = checkpoint["scaler_var"]  # âœ… scale_ ëŒ€ì‹  var_ ì‚¬ìš©

        max_qr_length = checkpoint["max_qr_length"]

        return model, encoder, scaler, max_qr_length
    return None, None, None, None
ğŸ“Œ ìµœì¢… ì •ë¦¬
ì›ì¸: StandardScalerì˜ .scale_ ì†ì„±ì´ ì—†ê¸° ë•Œë¬¸
í•´ê²°: .scale_ì„ .var_ë¡œ ë³€ê²½í•˜ë©´ í•´ê²°ë¨
ìˆ˜ì •í•œ ë¶€ë¶„: