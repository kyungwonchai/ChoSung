import pdfplumber
import re
from typing import List, Dict, Any
from collections import defaultdict

# ==============================================================================
# 데이터 구조 클래스 (변경 없음)
# ==============================================================================
class TextElement:
    def __init__(self, element: Dict[str, Any]):
        self.value = element.get('text', '')
        self.x0 = round(element.get('x0', 0), 2)
        self.top = round(element.get('top', 0), 2)
        self.x1 = round(element.get('x1', 0), 2)
        self.bottom = round(element.get('bottom', 0), 2)
        self.size = round(element.get('size', 0), 2)
        self.color = element.get('non_stroking_color', (0, 0, 0))

class PartComponent:
    def __init__(self, page_number: int, part_number_element: TextElement):
        self.page_number = page_number
        self.part_number = part_number_element
        self.related_elements: List[TextElement] = []

    def add_element(self, element: TextElement):
        self.related_elements.append(element)

    def get_details_string(self) -> str:
        if not self.related_elements: return "No other details found."
        sorted_elements = sorted(self.related_elements, key=lambda e: (e.top, e.x0))
        details_list = [
            f"Color: {e.color}, Size: {e.size}, Value: '{e.value}', Position: (x0={e.x0}, top={e.top}, x1={e.x1}, bottom={e.bottom})"
            for e in sorted_elements
        ]
        return ",\n\t".join(details_list)

# ==============================================================================
# ? '중간 지점 분할' 로직이 적용된 메인 함수 ?
# ==============================================================================
def analyze_parts_from_pdf(pdf_path: str, output_txt_path: str):
    all_part_components = []
    part_number_pattern = re.compile(r"^\d{4}-\d{6}$")

    print(f"PDF 분석 시작: {pdf_path}")
    try:
        with pdfplumber.open(pdf_path) as pdf:
            for page_num, page in enumerate(pdf.pages, 1):
                print(f"\n--- 페이지 {page_num} 처리 시작 ---")
                
                raw_words = page.extract_words(extra_attrs=["size", "non_stroking_color"])
                
                # 'top', 'bottom' 키를 가진 유효한 객체만 필터링
                sanitized_words = [w for w in raw_words if 'top' in w and 'bottom' in w and w['bottom'] > w['top']]

                if not sanitized_words:
                    print(f"페이지 {page_num}에서 유효한 텍스트를 찾지 못했습니다.")
                    continue

                # 1. ? 페이지의 모든 부품 번호를 찾아 수직으로 정렬합니다. (기준점 설정)
                anchors = sorted(
                    [w for w in sanitized_words if part_number_pattern.match(w.get('text', ''))],
                    key=lambda w: w['top']
                )

                if not anchors:
                    print(f"페이지 {page_num}에서 부품 번호를 찾지 못했습니다.")
                    continue
                
                print(f"페이지 {page_num}에서 {len(anchors)}개의 부품 번호(기준점)를 찾았습니다.")

                # 2. ? 각 부품 번호 사이의 중간 지점을 찾아 경계선을 설정합니다.
                boundaries = []
                for i in range(len(anchors) - 1):
                    midpoint = (anchors[i]['bottom'] + anchors[i+1]['top']) / 2
                    boundaries.append(midpoint)

                # 3. ? 설정된 경계선을 기준으로 전체 텍스트를 그룹으로 나눕니다.
                for i, anchor in enumerate(anchors):
                    # 그룹의 수직 범위 설정
                    group_top = boundaries[i-1] if i > 0 else 0
                    group_bottom = boundaries[i] if i < len(boundaries) else page.height
                    
                    # 현재 그룹에 속하는 단어들을 모두 찾습니다.
                    words_in_group = [
                        w for w in sanitized_words
                        if group_top <= w['top'] and w['bottom'] <= group_bottom
                    ]
                    
                    # PartComponent 객체 생성
                    part_element = TextElement(anchor)
                    component = PartComponent(page_num, part_element)
                    for word_obj in words_in_group:
                        if word_obj is not anchor:
                            component.add_element(TextElement(word_obj))
                    all_part_components.append(component)

        # 4. 최종 결과를 페이지별로 출력
        page_map = defaultdict(list)
        for component in all_part_components:
            page_map[component.page_number].append(component)

        with open(output_txt_path, 'w', encoding='utf-8') as f:
            f.write(f"총 {len(all_part_components)}개의 부품을 {len(page_map)}개 페이지에서 찾았습니다.\n")
            for page_num in sorted(page_map.keys()):
                components_on_page = page_map[page_num]
                f.write("\n" + "="*25 + f" PAGE {page_num} " + "="*25 + "\n")
                f.write(f"({len(components_on_page)}개의 부품 발견)\n\n")
                for i, component in enumerate(components_on_page, 1):
                    f.write(f"--- {i}. PartNumber: {component.part_number.value} ---\n")
                    f.write(f"Details: [\n\t{component.get_details_string()}\n]\n")
                    f.write("-" * 60 + "\n")

        print(f"\n분석 완료! 결과가 '{output_txt_path}' 파일에 저장되었습니다.")

    except Exception as e:
        print(f"스크립트 실행 중 오류가 발생했습니다: {e}")
        import traceback; traceback.print_exc()

# --- 메인 실행 부분 ---
if __name__ == "__main__":
    pdf_file_path = "YOUR_PDF_FILE_PATH.pdf" 
    output_file_path = "part_list_final_output.txt"
    analyze_parts_from_pdf(pdf_file_path, output_file_path)