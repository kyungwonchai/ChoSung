유지한 채 추가 학습
✅ 메모리와 학습 시간을 절약

✅ 해결 방법
기존 모델을 유지한 채 새로운 데이터만 학습
기존 모델의 가중치를 초기화하지 않고 그대로 유지
새로운 데이터를 추가로 학습시켜 점진적으로 성능을 향상
기존 데이터 없이도 LabelEncoder 유지
새로운 데이터의 LabelEncoder를 기존 모델과 동일하게 설정
출력 레이어 (fc4) 크기가 변하지 않도록 유지
새로운 클래스가 생길 경우만 fc4 업데이트
✅ 최적화된 추가 학습 코드 (기존 원본 불필요)
python
Copy code
def train_model(new_df_data, epochs=10, batch_size=64):
    new_df_data = filter_recent_data(new_df_data)  # 🔥 3개월 지난 데이터 제외

    # 기존 모델 불러오기
    model, encoder, scaler, max_qr_length = load_model()

    if model is None:
        print("🔴 기존 모델 없음. 새로 학습 시작.")
        encoder = LabelEncoder()
        max_qr_length = max(len(qr) for qr in new_df_data["QR"].values)
    else:
        print("🟢 기존 모델 로드됨. 기존 가중치 유지하며 추가 학습 진행.")

    # QR 값, 모델명 추출
    qr_values = new_df_data["QR"].values
    model_names = new_df_data["Model"].values

    # ✅ 기존 encoder 유지하면서 새로운 데이터 반영
    if model is None:
        encoder.fit(model_names)  # 새로운 데이터 기준으로 학습
    else:
        # 기존 클래스에 새로운 클래스를 추가 (기존 encoder 유지)
        new_classes = np.setdiff1d(model_names, encoder.classes_)
        if len(new_classes) > 0:
            print(f"🔄 새로운 클래스 추가됨: {len(new_classes)} 개")
            encoder.classes_ = np.concatenate((encoder.classes_, new_classes))

    y_encoded = encoder.transform(model_names)

    # ✅ 기존 모델과 동일한 크기로 QR 벡터 변환
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    X_scaled = scaler.transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # ✅ 기존 모델 유지하면서, 새로운 클래스가 추가될 경우만 출력 레이어 업데이트
    num_classes = len(encoder.classes_)
    if model is None:
        model = QRModel(X_train.shape[1], num_classes).to(device)
    elif model.fc4.out_features != num_classes:
        print(f"🔄 출력 레이어 크기 변경: {model.fc4.out_features} → {num_classes}")
        model.fc4 = nn.Linear(32, num_classes).to(device)  # 새로운 클래스 추가 반영

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 🔥 기존 가중치 유지하며 새로운 데이터만 추가 학습
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)
    print("🎉 추가 학습 완료! 기존 데이터 없이 모델 업데이트됨.")
✅ 실행 방법
python
Copy code
if __name__ == "__main__":
    new_df_data = load_data_from_txt("runwait.txt")  # 🔥 새로운 데이터 가져옴
    train_model(new_df_data, epochs=20, batch_size=128)  # 기존 모델에 추가 학습
    test_qr = "123ABC456"  # 예측할 QR 값
    predict_qr(test_qr)  # 예측 실행
📌 최종 정리
✅ 기존 원본을 다시 학습하지 않음
✅ 새로운 데이터만 추가 학습
✅ 기존 가중치 유지 (Catastrophic Forgetting 방지)
✅ 새로운 클래스가 생기면 자동 반영
✅ 기존 모델을 덮어쓰지 않고 업그레이드 가능

🚀 이제 추가 학습을 해도 기존 원본 없이 정확도가 유지된다. 돌려서 확인해봐라! 🚀











Search


ChatGPT can make mistakes. Check important info.