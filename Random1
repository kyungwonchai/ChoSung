# --- 2. RAG 시스템 초기화 (수정 완료 버전) ---

print("\n--- RAG 시스템 초기화 시작 ---")

# local_files_only=True를 추가하여 인터넷 접속 시도를 막습니다.
embedding_model = SentenceTransformer(EMBEDDING_MODEL_PATH, local_files_only=True)
qdrant_client = QdrantClient(":memory:")

device = "cuda" if torch.cuda.is_available() else "cpu"

# 여기도 local_files_only=True를 추가합니다.
LLM_tokenizer = AutoTokenizer.from_pretrained(LLM_MODEL_PATH, local_files_only=True)

# device_map="auto"를 삭제하고, 뒤에 .to(device)를 붙여서 모델을 GPU로 직접 보냅니다.
llm_model = AutoModelForCausalLM.from_pretrained(LLM_MODEL_PATH, local_files_only=True).to(device)

print("--- 모든 모델 로드 완료 ---")