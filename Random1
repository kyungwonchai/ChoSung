래는 요청하신 기능을 Jupyter Notebook에서 구현하기 위한 전체 코드입니다. 모델 생성 부분과 예측 및 시각화 부분을 분리하여 두 개의 독립된 셀로 구성했습니다.

1. 모델 생성 코드 (학습 및 모델 저장)
이 코드에서는 PandB 데이터를 학습하여 XGBoost 및 K-Fold 교차 검증을 사용해 최적의 모델을 생성하고 저장합니다.

python
코드 복사
# 필요한 라이브러리 설치
!pip install pandas scikit-learn xgboost matplotlib --quiet

# 필요한 라이브러리 임포트
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, KFold
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor
import joblib  # 모델 저장을 위한 라이브러리

# 데이터 불러오기
# PandB 데이터 불러오기
# PandB는 예제 데이터로 가정, 실제 데이터 경로를 설정하세요
data = pd.read_csv('PandB.csv')  # PandB 데이터를 불러옵니다.

# 데이터 준비
# PandB의 마지막 열을 target 변수로 사용하고, 나머지는 feature로 사용
X = data.iloc[:, :-1].values  # 특징 데이터
y = data.iloc[:, -1].values  # 타겟 데이터

# 모델 학습 및 검증
kf = KFold(n_splits=5, shuffle=True, random_state=42)
xgb_model = XGBRegressor(random_state=42, n_estimators=100, max_depth=5)

mse_scores = []

# K-Fold 교차 검증
for train_idx, val_idx in kf.split(X):
    X_train, X_val = X[train_idx], X[val_idx]
    y_train, y_val = y[train_idx], y[val_idx]

    # 모델 학습
    xgb_model.fit(X_train, y_train)
    
    # 검증
    predictions = xgb_model.predict(X_val)
    mse = mean_squared_error(y_val, predictions)
    mse_scores.append(mse)

# 평균 MSE 출력
print(f"Mean MSE across folds: {np.mean(mse_scores):.4f}")

# 모델 저장
joblib.dump(xgb_model, 'xgb_model.pkl')  # 학습된 모델을 저장
print("Model saved as 'xgb_model.pkl'")
2. 예측 및 시각화 코드 (모델 사용)
이 코드에서는 저장된 모델을 불러와 pnowab 값을 예측하고, 결과를 시각화합니다.

python
코드 복사
# 필요한 라이브러리 임포트
import joblib
import matplotlib.pyplot as plt
import numpy as np

# 모델 불러오기
model = joblib.load('xgb_model.pkl')  # 저장된 모델 불러오기

# 예측할 데이터 pnowab (1개 행의 데이터)
pnowab = np.array([[1.2, 3.4, 5.6, 7.8]])  # 예제 데이터, 실제 값으로 대체 필요

# 예측 수행
predicted = model.predict(pnowab).flatten()  # 예측값
print(f"Predicted values: {predicted}")

# 실제값 (예제용, 실제 데이터로 대체)
actual = np.array([1.1, 3.5, 5.4, 7.9])  # pnowab의 실제 값

# 시각화: 예측값과 실제값 비교
features = ['ap', 'bp', 'cp', 'dp']

# 차트 생성
plt.figure(figsize=(10, 6))

# 예측값 선 연결
plt.plot(features, predicted, label='Predicted', linestyle='--', marker='o')

# 실제값 점 표시
plt.scatter(features, actual, color='red', label='Actual', zorder=5)

# 오차 표시
for i, (pred, act) in enumerate(zip(predicted, actual)):
    plt.plot([features[i], features[i]], [pred, act], 'k--', alpha=0.7)

# 레이블 및 제목
plt.title("Prediction vs Actual")
plt.xlabel("Features")
plt.ylabel("Values")
plt.legend()
plt.grid()
plt.show()

# 오차 점수 시각화
errors = np.abs(predicted - actual)  # 오차 계산
error_scores = 100 - (errors / np.max(errors) * 100)  # 100점 만점 기준

plt.figure(figsize=(10, 6))
plt.bar(features, error_scores, color='blue', alpha=0.7)
plt.axhline(100, color='green', linestyle='--', label='Max Score (100)')
plt.title("Error Score (100-point scale)")
plt.xlabel("Features")
plt.ylabel("Score")
plt.legend()
plt.ylim(0, 100)
plt.grid()
plt.show()

# 오차 점수 출력
print(f"Error Scores (100-point scale): {error_scores}")
구성 요약
모델 생성 및 저장 코드:

PandB 데이터를 학습하여 최적의 모델을 생성하고 저장.
XGBoost 모델과 K-Fold 교차 검증을 활용.
모델 사용 및 시각화 코드:

저장된 모델을 불러와 pnowab 데이터를 예측.
예측값과 실제값의 차이를 시각화하고, 오차 점수를 100점 만점으로 계산하여 막대 그래프로 표시.
결과
예측 vs 실제 비교 차트:

예측값은 선으로 연결, 실제값은 점으로 표시.
예측값과 실제값 사이의 차이를 시각적으로 보여줌.
오차 점수 차트:

각 특징(feature)에 대한 정확도를 100점 만점으로 계산하여 막대 그래프로 표시.
참고
PandB 및 pnowab 데이터는 실제 데이터를 사용해야 합니다.
pnowab는 반드시 모델이 학습한 데이터와 동일한 형식이어야 합니다.