네, 직접 파이썬 코드로 RAG 시스템을 구현하는 전체 과정을 아주 상세하게 안내해 드리겠습니다. 에이전트 빌더에서 컴포넌트를 연결하던 개념을 실제 코드로 옮기는 과정이라고 생각하시면 됩니다.

이 코드는 PyCharm 같은 개발 환경에서 바로 실행할 수 있습니다.

## 0단계: 개발 환경 준비 ?????
먼저 필요한 라이브러리들을 설치해야 합니다. PyCharm 터미널에 아래 명령어들을 한 줄씩 입력하여 실행하세요.

Bash

pip install qdrant-client pandas
pip install sentence-transformers
pip install transformers torch
## 1단계: 데이터 준비 (CSV) ??
먼저, 우리가 Qdrant에 저장할 원본 데이터를 준비합니다. 예시로 사용했던 부품 데이터를 CSV 파일(smd_data.csv)로 만들었다고 가정하겠습니다.

smd_data.csv 파일 내용:

코드 스니펫

PartName,Description,PickupSpeed,MountSpeed
2203-006423,저전력 소형 칩 저항기,60,100
2501-001178,고주파수용 세라믹 콘덴서,55,90
3711-008123,데이터 전송용 USB 커넥터,30,50
## 2단계: '번역가'와 '도서관' 준비 ??
이제 코드에서 임베딩 모델('번역가')과 Qdrant('도서관')를 설정합니다.

Python

# 필요한 도구들을 불러옵니다.
import pandas as pd
from qdrant_client import QdrantClient, models
from sentence_transformers import SentenceTransformer
from transformers import pipeline

# 1. '번역가' 준비 (허깅페이스 임베딩 모델)
# 이 모델이 텍스트를 벡터로 바꿔줍니다.
print("임베딩 모델을 로드합니다...")
embedding_model = SentenceTransformer('jhgan/ko-sbert-nli')
print("모델 로드 완료.")

# 2. '도서관' 준비 (Qdrant 클라이언트)
# :memory:는 테스트용으로, 프로그램을 끄면 데이터가 사라집니다.
qdrant_client = QdrantClient(":memory:")

# 도서관에 'smd_parts'라는 서가(컬렉션)를 만듭니다.
# vector_size는 '번역가'가 만드는 번역본(벡터)의 크기와 같아야 합니다.
qdrant_client.recreate_collection(
    collection_name="smd_parts",
    vectors_config=models.VectorParams(
        size=embedding_model.get_sentence_embedding_dimension(),
        distance=models.Distance.COSINE
    )
)
print("'smd_parts' 컬렉션 생성 완료.")
## 3단계: 데이터 주입 (도서관에 책 정리하기)
CSV 파일의 데이터를 Qdrant에 저장하는 과정입니다. 이전 질문에서 '파싱'에 해당되는 부분입니다.

Python

# 1. CSV 파일 읽기
df = pd.read_csv('smd_data.csv')

# 2. Qdrant에 넣을 형태로 데이터 가공
points_to_ingest = []
for idx, row in df.iterrows():
    # 검색의 기준이 될 텍스트를 만듭니다.
    text_to_embed = f"부품명: {row['PartName']}, 설명: {row['Description']}"
    
    # '번역가'를 이용해 텍스트를 벡터로 번역합니다.
    vector = embedding_model.encode(text_to_embed).tolist()
    
    # 원본 데이터는 payload에 저장합니다.
    payload = row.to_dict()
    
    # Qdrant가 좋아하는 PointStruct 형태로 정리합니다.
    point = models.PointStruct(
        id=idx,
        vector=vector,
        payload=payload
    )
    points_to_ingest.append(point)

# 3. 정리된 데이터를 Qdrant에 한번에 주입(Ingest)합니다.
qdrant_client.upsert(
    collection_name="smd_parts",
    points=points_to_ingest,
    wait=True
)
print(f"{len(points_to_ingest)}개의 데이터를 Qdrant에 주입했습니다.")
## 4단계: RAG 함수 구현 (검색 후 답변 생성) ??
이제 사용자의 질문을 받아서 검색하고, LLM을 이용해 최종 답변을 생성하는 핵심 함수를 만듭니다.

Python

# '리포트 작성가'(LLM L3)를 준비합니다.
# 여기서는 SKT에서 만든 한국어 모델(KoGPT2)을 사용합니다.
print("답변 생성 모델(LLM)을 로드합니다...")
generator = pipeline('text-generation', model='skt/kogpt2-base-v2')
print("LLM 로드 완료.")


def ask_rag(question: str):
    # 1. 검색 (Retrieval)
    # 사용자 질문을 '번역가'를 이용해 벡터로 변환합니다.
    question_vector = embedding_model.encode(question).tolist()
    
    # Qdrant에서 질문 벡터와 가장 유사한 정보 조각(책)을 찾습니다.
    hits = qdrant_client.search(
        collection_name="smd_parts",
        query_vector=question_vector,
        limit=1  # 가장 유사한 1개만 가져오기
    )
    
    # 검색된 정보(책 내용)를 `context` 변수에 정리합니다.
    if not hits:
        return "관련 정보를 찾을 수 없습니다."
        
    context = ""
    for hit in hits:
        # payload에 저장된 원본 데이터를 사용합니다.
        payload = hit.payload
        context += f"부품명: {payload.get('PartName')}, 설명: {payload.get('Description')}, 흡착속도: {payload.get('PickupSpeed')}, 장착속도: {payload.get('MountSpeed')}\n"

    # 2. 생성 (Generation)
    # '리포트 작성가'(LLM)에게 전달할 지시서(프롬프트)를 만듭니다.
    prompt = f"""
    아래 '참고 자료'만을 바탕으로 '질문'에 대해 답변해줘. 참고 자료에 없는 내용은 절대로 언급하지 마.

    [참고 자료]
    {context}

    [질문]
    {question}

    [답변]
    """
    
    # 지시서를 전달하여 답변을 생성합니다.
    response = generator(prompt, max_length=150)
    
    # 생성된 답변에서 필요한 부분만 추출하여 반환합니다.
    return response[0]['generated_text'].split('[답변]')[1].strip()

## 5단계: 실행 및 테스트
이제 만든 함수를 직접 호출해서 결과를 확인합니다.

Python

# 테스트 1: 부품 번호로 정확하게 질문하기
query1 = "2203-006423의 흡착 속도와 장착 속도는?"
answer1 = ask_rag(query1)
print(f"\n[질문 1]\n{query1}")
print(f"[답변 1]\n{answer1}")

# 테스트 2: 부품 번호 없이 자연어로 질문하기
query2 = "그 작은 칩 저항기의 속도 정보 좀 알려줘"
answer2 = ask_rag(query2)
print(f"\n[질문 2]\n{query2}")
print(f"[답변 2]\n{answer2}")

이 전체 코드를 하나의 파이썬 파일(.py)로 저장하고 실행하면, 데이터 준비부터 RAG 답변 생성까지 모든 과정을 직접 확인할 수 있습니다.