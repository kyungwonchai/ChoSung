된 파일을 제공해드리겠습니다. 먼저, 모델 학습을 위한 파일을 생성합니다.

train_model.py (모델 학습용 파일):

python

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from Levenshtein import distance
import joblib

def preprocess_data(data):
    # 데이터 전처리 작업 수행
    preprocessed_data = ...

    return preprocessed_data

def train_model(data):
    # 데이터 전처리
    preprocessed_data = preprocess_data(data)

    # 벡터 변환
    vectorizer = CountVectorizer()
    parts_vector = vectorizer.fit_transform(preprocessed_data)

    # 유사도 계산
    similarity_matrix = cosine_similarity(parts_vector)

    return similarity_matrix, vectorizer

def save_model(similarity_matrix, vectorizer, model_file, vectorizer_file):
    # 모델 저장
    model_data = {'similarity_matrix': similarity_matrix, 'vectorizer': vectorizer}
    joblib.dump(model_data, model_file)
    vectorizer.save(vectorizer_file)

# 데이터베이스에서 데이터 추출
# 예시 데이터를 데이터프레임으로 가정하고 부품코드 컬럼이 있다고 가정합니다.
data = pd.read_sql_query("SELECT 부품코드 FROM 테이블명", connection)

# 모델 학습
similarity_matrix, vectorizer = train_model(data['부품코드'])

# 학습된 모델 저장
save_model(similarity_matrix, vectorizer, 'model.pkl', 'vectorizer.pkl')

위의 코드에서 preprocess_data() 함수는 데이터 전처리 작업을 수행하는 부분입니다. 데이터에 대해 필요한 전처리 작업을 수행하여 적절한 형태로 가공해야 합니다.

train_model() 함수는 데이터를 전처리하고, 벡터 변환을 수행하며, 유사도를 계산하여 유사도 행렬을 반환합니다.

save_model() 함수는 학습된 모델과 벡터 변환기를 저장하는 역할을 합니다. model_data를 joblib를 사용하여 파일로 저장하여 나중에 불러와 사용할 수 있습니다.

이제 UI와 상호작용하는 파일을 생성합니다.

ui.py (UI 파일):

python

import tkinter as tk
import joblib
from Levenshtein import distance

def load_model(model_file, vectorizer_file):
    # 모델 로드
    model_data = joblib.load(model_file)
    similarity_matrix = model_data['similarity_matrix']
    vectorizer = model_data['vectorizer']

    return similarity_matrix, vectorizer

def find_similar_parts(input_text, similarity_matrix, vectorizer, parts_data):
    # 입력된 텍스트와 각 부품코드의 유사도 계산
    input_vector = vectorizer.transform([input_text])
    similarity_scores = cosine_similarity(input_vector, similarity_matrix).flatten()

    # 유사도가 가장 높은 순서대로 정렬하여 상위 10개 부품코드 추출
    top_indices = similarity_scores.argsort()[:-11:-1

User
이어서
ChatGPT

python

    similar_parts = parts_data[top_indices]

    # Levenshtein 거리를 계산하여 가장 유사한 순서로 정렬
    similarity_scores = [distance(input_text, part) for part in similar_parts]
    similar_parts_with_distance = sorted(zip(similarity_scores, similar_parts))

    return similar_parts_with_distance

def show_similar_parts():
    input_text = input_entry.get()

    # 저장된 모델 로드
    similarity_matrix, vectorizer = load_model('model.pkl', 'vectorizer.pkl')

    # 유사한 부품코드 검색
    similar_parts = find_similar_parts(input_text, similarity_matrix, vectorizer, parts_data)

    # 결과 출력
    result_text = '\n'.join(f'{part}: {distance}' for distance, part in similar_parts)
    result_label.config(text=result_text)

# 판다스 데이터프레임으로부터 부품코드 데이터를 로드
parts_data = pd.read_csv('부품코드.csv')['부품코드'].values

# tkinter 윈도우 생성
window = tk.Tk()
window.title('부품코드 유사도 검색')

# 입력 텍스트박스
input_entry = tk.Entry(window)
input_entry.pack()

# 검색 버튼
search_button = tk.Button(window, text='검색', command=show_similar_parts)
search_button.pack()

# 결과 텍스트 레이블
result_label = tk.Label(window, text='')
result_label.pack()

window.mainloop()

위의 코드는 load_model() 함수를 사용하여 저장된 모델을 로드하고, find_similar_parts() 함수를 사용하여 유사한 부품코드를 검색합니다. show_similar_parts() 함수는 UI에서 검색 버튼을 클릭했을 때 호출되며, 사용자가 입력한 텍스트를 기반으로 유사한 부품코드를 검색하고 결과를 UI에 출력합니다.

show_similar_parts() 함수 내에서 저장된 모델을 로드하고, find_similar_parts() 함수를 호출하여 유사한 부품코드를 검색합니다. 그 후, 결과를 텍스트 형식으로 가공하여 UI의 레이블에 표시합니다.

마지막으로, parts_data 변수는 pd.read_csv('부품코드.csv')['부품코드'].values를 통해 부품코드 데이터를 로드하도록 설정해주셔야 합니다. 데이터 파일 경로 및 로드 방식에 맞게 수정해주십시오.

이제 모델 학습용 파일인 train_model.py와 UI 파일인 ui.py를 각각 실행하여 학습과 UI 기능을 분리하여 사용할 수 있습니다.