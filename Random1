방법 ② 모델 수동 다운로드(회사망 뚫기 어려울 때)
인터넷 안 되는 회사망이면,
집이나 인터넷 되는 환경에서 모델 파일 받아서 옮기는 게 속 편함.

(1) 수동으로 모델 파일 다운로드:
집이나 핸드폰 핫스팟 등 인터넷 되는 곳에서:
https://huggingface.co/TheBloke/CodeLlama-7B-GGUF
codellama-7b.Q4_K_M.gguf 파일 받기 (약 3.8GB)
(2) 파일 복사해서 회사 PC에 옮기기 (USB든 뭐든)
파일 위치:
C:\Users\사용자명\.ollama\models\codellama-7b 폴더 만들고 .gguf 파일 넣기
(3) modelfile 만들기
codellama-7b 폴더 안에 메모장 열어서 아래처럼 작성:

bash
복사
편집
FROM ./codellama-7b.Q4_K_M.gguf
파일명: modelfile
확장자 없이 저장!

(4) 실행 테스트:
bash
복사
편집
ollama run codellama:7b
→ 실행되면 성공.

방법 ③ 집에서 전체 설치 + 모델까지 다운 → 회사PC로 옮기기
집 컴퓨터에 Ollama 설치하고 모델 다운 완료까지 함.
집 PC에서 이 폴더 복사:
makefile
복사
편집
C:\Users\내아이디\.ollama\
이걸 USB나 외장하드로 회사PC 같은 위치에 복사.
→ 이러면 프록시, 인터넷 설정 상관없이 바로 됨.