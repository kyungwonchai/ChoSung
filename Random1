âœ… ë¼ì¸ ê°’ì´ ë¬¸ìë¼ë©´, ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ê³  ìˆ«ìë¡œ ë³€í™˜í•´ì•¼ í•¨
âœ… ë¬¸ìí˜• ë¼ì¸ì„ Label Encodingí•˜ì—¬ ìˆ«ìë¡œ ë³€í™˜ í›„ í•™ìŠµì— í¬í•¨
âœ… í›ˆë ¨ ë°ì´í„°ì—ì„œëŠ” LabelEncoderë¥¼ ì‚¬ìš©í•˜ì—¬ ë³€í™˜í•˜ê³ , ì˜ˆì¸¡ ì‹œì—ë„ ë™ì¼í•œ ë³€í™˜ ì ìš©

âœ… ìµœì¢… ì½”ë“œ (ë¼ì¸ì„ Label Encodingí•˜ì—¬ ìˆ«ìë¡œ ë³€í™˜)
python
Copy code
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data_utils
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# ğŸ“Œ TXT íŒŒì¼ì—ì„œ ë°ì´í„° ì½ê¸° (ë¼ì¸ í¬í•¨í•˜ì—¬ í•™ìŠµ)
def load_data_from_txt(file_path, sample_ratio=0.1):
    with open(file_path, "r", encoding="utf-8") as f:
        lines = f.readlines()

    # ğŸ”¹ "ë¼ì¸, ì‹œê°„, ëª¨ë¸ëª…, QR ì½”ë“œ" ê°’ë§Œ ì¶”ì¶œ
    data = [line.strip().split()[:4] for line in lines if len(line.strip().split()) >= 4]
    df = pd.DataFrame(data, columns=["Line", "Time", "Model", "QR"])

    # ğŸ”¹ ì‹œê°„(Time) ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ í›„ ì •ë ¬
    df["Time"] = pd.to_numeric(df["Time"], errors="coerce")
    df = df.sort_values(by=["Line", "Time"]).reset_index(drop=True)

    # ğŸ”¹ ë¼ì¸ë³„ë¡œ ìƒ˜í”Œë§ ìˆ˜í–‰ (ê° ë¼ì¸ë³„ ì¼ì • ë¹„ìœ¨ ìœ ì§€)
    df_sampled = df.groupby("Line").apply(lambda x: x.sample(frac=sample_ratio, random_state=42)).reset_index(drop=True)

    return df_sampled

# ğŸ“Œ QR ê°’ì„ ìˆ«ì ë²¡í„°ë¡œ ë³€í™˜ + ë¼ì¸ ì •ë³´ë¥¼ ìˆ«ìë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€
def vectorize_qr_with_line(qr_values, line_values, line_encoder, max_length=10):
    vectorized = np.zeros((len(qr_values), max_length + 1), dtype=np.int32)  # QR ê¸¸ì´ + ë¼ì¸ ì •ë³´
    for i, (qr, line) in enumerate(zip(qr_values, line_values)):
        for j, char in enumerate(qr[:max_length]):  # QRì„ ìˆ«ìë¡œ ë³€í™˜
            vectorized[i, j] = ord(char)
        vectorized[i, -1] = line_encoder.transform([line])[0]  # ë§ˆì§€ë§‰ ìœ„ì¹˜ì— ë³€í™˜ëœ ë¼ì¸ ê°’ ì¶”ê°€
    return vectorized

# ğŸ“Œ MLP ê¸°ë°˜ QR ëª¨ë¸ ì •ì˜ (ë¼ì¸ ì •ë³´ í¬í•¨)
class QRMLPModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super(QRMLPModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, num_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.fc4(x)  # ìµœì¢… ì¶œë ¥
        return x

# ğŸ“Œ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ (í›ˆë ¨ í›„ ê²€ì¦ ê²°ê³¼ í¬í•¨)
def train_and_validate_model(df_data, epochs=20, batch_size=64, learning_rate=0.001):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # ğŸ”¹ ë°ì´í„° ì „ì²˜ë¦¬ (ë¼ì¸ í¬í•¨)
    qr_values = df_data["QR"].values
    line_values = df_data["Line"].values  # ë¼ì¸ ê°’ ì¶”ê°€
    model_names = df_data["Model"].values

    # Label Encoding (ëª¨ë¸ëª… ë° ë¼ì¸ ê°’ì„ ìˆ«ìë¡œ ë³€í™˜)
    model_encoder = LabelEncoder()
    line_encoder = LabelEncoder()

    y_encoded = model_encoder.fit_transform(model_names)
    line_encoded = line_encoder.fit_transform(line_values)

    # QR ì½”ë“œ ë²¡í„°í™” (ë¼ì¸ ì •ë³´ í¬í•¨)
    X_vectorized = vectorize_qr_with_line(qr_values, line_values, line_encoder, max_length=10)

    # ğŸ”¹ ë°ì´í„°ì…‹ ë¶„í•  (Train 70%, Validation 30%)
    X_train, X_val, y_train, y_val = train_test_split(X_vectorized, y_encoded, test_size=0.3, random_state=42)

    # PyTorch ë°ì´í„° ë¡œë” ìƒì„±
    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32), torch.tensor(y_train, dtype=torch.long))
    val_dataset = data_utils.TensorDataset(torch.tensor(X_val, dtype=torch.float32), torch.tensor(y_val, dtype=torch.long))

    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    val_loader = data_utils.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

    # ëª¨ë¸ ì´ˆê¸°í™”
    model = QRMLPModel(input_size=X_vectorized.shape[1], num_classes=len(model_encoder.classes_)).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)

    # ğŸ”¹ í›ˆë ¨ ê³¼ì •
    train_losses = []
    val_losses = []
    val_accuracies = []

    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        train_losses.append(avg_loss)

        # ğŸ”¹ ê²€ì¦ ê³¼ì •
        model.eval()
        val_loss = 0
        correct = 0
        total = 0
        with torch.no_grad():
            for inputs, targets in val_loader:
                inputs, targets = inputs.to(device), targets.to(device)
                outputs = model(inputs)
                val_loss += criterion(outputs, targets).item()
                predicted = torch.argmax(outputs, dim=1)
                correct += (predicted == targets).sum().item()
                total += targets.size(0)

        val_loss /= len(val_loader)
        accuracy = correct / total
        val_losses.append(val_loss)
        val_accuracies.append(accuracy)

        print(f"Epoch [{epoch+1}/{epochs}] - Loss: {avg_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {accuracy:.4f}")

    print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
    
    # ğŸ”¹ ê²€ì¦ ê²°ê³¼ ì‹œê°í™”
    plot_validation_results(train_losses, val_losses, val_accuracies)

    return model, model_encoder, line_encoder

# ğŸ“Œ ê²€ì¦ ê²°ê³¼ ì‹œê°í™” í•¨ìˆ˜
def plot_validation_results(train_losses, val_losses, val_accuracies):
    plt.figure(figsize=(12, 5))

    # ğŸ”¹ Loss ê·¸ë˜í”„
    plt.subplot(1, 2, 1)
    plt.plot(train_losses, label="Train Loss", marker="o")
    plt.plot(val_losses, label="Validation Loss", marker="o")
    plt.xlabel("Epoch")
    plt.ylabel("Loss")
    plt.title("Train vs Validation Loss")
    plt.legend()

    # ğŸ”¹ Accuracy ê·¸ë˜í”„
    plt.subplot(1, 2, 2)
    plt.plot(val_accuracies, label="Validation Accuracy", marker="o", color="green")
    plt.xlabel("Epoch")
    plt.ylabel("Accuracy")
    plt.title("Validation Accuracy")
    plt.legend()

    plt.show()

# ğŸ“Œ ì˜ˆì¸¡ í•¨ìˆ˜ (ë¼ì¸ ì •ë³´ë„ ì…ë ¥)
def predict_qr(model, model_encoder, line_encoder, qr_value, line_value):
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    max_qr_length = 10  # ê¸°ì¡´ ëª¨ë¸ê³¼ ë™ì¼í•œ ê¸¸ì´
    X_vectorized = vectorize_qr_with_line([qr_value], [line_value], line_encoder, max_length=max_qr_length)

    # ğŸ”¹ ì˜ˆì¸¡ ìˆ˜í–‰
    model.eval()
    with torch.no_grad():
        inputs = torch.tensor(X_vectorized, dtype=torch.float32).to(device)
        outputs = model(inputs)
        predicted = torch.argmax(outputs, dim=1).cpu().numpy()[0]
    
    predicted_model = model_encoder.inverse_transform([predicted])[0]
    print(f"âœ… ì˜ˆì¸¡ëœ ëª¨ë¸: {predicted_model}")

# ğŸ“Œ ì‹¤í–‰ ì˜ˆì œ
if __name__ == "__main__":
    txt_file_path = "runwait.txt"  # ğŸ”¥ QR ë°ì´í„°ê°€ í¬í•¨ëœ TXT íŒŒì¼ ê²½ë¡œ
    df_data = load_data_from_txt(txt_file_path, sample_ratio=0.1)  # ğŸ”¥ ë°ì´í„° ìƒ˜í”Œë§
    
    # ğŸ”¥ ëª¨ë¸ í•™ìŠµ ë° ê²€ì¦ ê³¼ì • í¬í•¨
    trained_model, trained_model_encoder, trained_line_encoder = train_and_validate_model(df_data, epochs=20)

    # ğŸ”¥ ì˜ˆì¸¡ ì˜ˆì œ (ë¼ì¸ ì •ë³´ í¬í•¨)
    test_qr = "123ABC456"  # ì˜ˆì¸¡í•  QR ê°’
    test_line = "LINE_A"  # ì˜ˆì¸¡í•  ë¼ì¸ ê°’