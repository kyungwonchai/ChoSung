아래는 **랜덤포레스트(Random Forest)**가 가장 좋은 모델로 선택되었을 경우, 해당 모델을 저장하고, 하이퍼파라미터 최적화(그리드 서치)를 추가로 수행할 수 있도록 한 전체 코드입니다.

코드: 랜덤포레스트 모델 선정 및 최적화
주요 기능:
최적 모델 저장:
여러 모델을 평가한 후, 가장 성능이 좋은 모델(예: 랜덤포레스트)을 **best_model.pkl**로 저장.
랜덤포레스트 하이퍼파라미터 최적화:
GridSearchCV를 통해 랜덤포레스트의 최적의 파라미터를 탐색.
하이퍼파라미터 최적화 결과를 반영하여 모델 재학습 및 평가.
코드
python
코드 복사
# 필요한 라이브러리 임포트
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, KFold, GridSearchCV
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import joblib

# 데이터 가져오기 함수
def fetch_data_from_db(proc_name):
    """
    MSSQL 저장 프로시저에서 데이터를 가져옵니다.
    :param proc_name: 저장 프로시저 이름
    :return: pandas DataFrame
    """
    import pymssql
    server = "localhost"
    user = "your_username"
    password = "your_password"
    database = "your_database"
    try:
        conn = pymssql.connect(server=server, user=user, password=password, database=database)
        query = f"EXEC {proc_name}"
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        print(f"Error fetching data: {e}")
        return pd.DataFrame()

# 데이터 준비
data = fetch_data_from_db("PRealAandB")
if data.empty:
    print("No data fetched. Exiting...")
    exit()

# 데이터 전처리
timestamps = data.iloc[:, 0]  # 시간 데이터 (첫 번째 열)
X = data.iloc[:, 2:5].values  # 특징 데이터 (3~5열)
y = data.iloc[:, 1].values    # 타겟 데이터 (2열)

# 학습 및 테스트 데이터 분리
X_train, X_test, y_train, y_test, timestamps_train, timestamps_test = train_test_split(
    X, y, timestamps, test_size=0.2, random_state=42
)

# 사용할 모델 정의
models = {
    "LinearRegression": LinearRegression(),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=100, random_state=42)
}

# 평가지표 저장 딕셔너리
results = {
    "Model": [],
    "MSE": [],
    "RMSE": [],
    "MAE": [],
    "R2_Score": []
}

# 모델 학습 및 평가
print("Training and evaluating models...")
for model_name, model in models.items():
    print(f"Training {model_name}...")
    
    # 모델 학습
    model.fit(X_train, y_train)
    
    # 예측
    y_pred = model.predict(X_test)
    
    # 평가지표 계산
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # 결과 저장
    results["Model"].append(model_name)
    results["MSE"].append(mse)
    results["RMSE"].append(rmse)
    results["MAE"].append(mae)
    results["R2_Score"].append(r2)
    
    print(f"{model_name}: MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}")

# 결과 데이터프레임 생성
results_df = pd.DataFrame(results)

# 최적 모델 선택 (MSE 기준)
best_model_idx = results_df["MSE"].idxmin()
best_model_name = results_df.loc[best_model_idx, "Model"]
print(f"\nBest model: {best_model_name} with MSE={results_df.loc[best_model_idx, 'MSE']:.4f}")

# 랜덤포레스트가 최적 모델이면 하이퍼파라미터 최적화 수행
if best_model_name == "RandomForest":
    print("\nOptimizing Random Forest hyperparameters...")
    
    # 파라미터 그리드 정의
    param_grid = {
        "n_estimators": [50, 100, 150],
        "max_depth": [None, 10, 20],
        "min_samples_split": [2, 5, 10],
        "min_samples_leaf": [1, 2, 4]
    }
    
    # GridSearchCV 설정
    rf = RandomForestRegressor(random_state=42)
    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring="neg_mean_squared_error", verbose=1)
    
    # 최적화 수행
    grid_search.fit(X_train, y_train)
    best_rf_model = grid_search.best_estimator_
    print(f"Best Random Forest parameters: {grid_search.best_params_}")
    
    # 최적화된 모델로 재평가
    y_pred_optimized = best_rf_model.predict(X_test)
    mse_optimized = mean_squared_error(y_test, y_pred_optimized)
    print(f"Optimized Random Forest MSE: {mse_optimized:.4f}")
    
    # 최적 모델 저장
    joblib.dump(best_rf_model, "best_model.pkl")
    print("Optimized Random Forest model saved as 'best_model.pkl'")
else:
    print(f"The best model is not Random Forest, saving {best_model_name} as 'best_model.pkl'")
    joblib.dump(models[best_model_name], "best_model.pkl")

# 시각화: 평가지표 비교
metrics = ["MSE", "RMSE", "MAE", "R2_Score"]
fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

for i, metric in enumerate(metrics):
    axes[i].bar(results_df["Model"], results_df[metric], color=["blue", "orange", "green"])
    axes[i].set_title(f"Comparison of {metric}")
    axes[i].set_ylabel(metric)
    axes[i].grid(axis="y")

plt.tight_layout()
plt.show()
코드 설명
1. 모델 평가
MSE, RMSE, MAE, R²를 계산하여 모델의 성능을 평가.
MSE가 가장 낮은 모델을 최적 모델로 선택.
2. 랜덤포레스트 최적화
**GridSearchCV**를 사용하여 랜덤포레스트의 하이퍼파라미터를 최적화.
최적의 파라미터로 모델을 재학습한 후 성능을 다시 평가.
3. 최적 모델 저장
최적 모델을 **best_model.pkl**로 저장.
최적 모델이 랜덤포레스트가 아닐 경우, 해당 모델을 저장.
4. 시각화
MSE, RMSE, MAE, R²를 비교하는 차트를 생성.
결과
최적 모델(예: 랜덤포레스트)을 자동으로 탐색 및 저장.
랜덤포레스트의 하이퍼파라미터 최적화 수행.