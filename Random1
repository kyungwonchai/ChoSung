가 발생한 이유는 파이썬 코드에서 이미 torch의 데이터셋 관련 모듈을

python
Copy code
import torch.utils.data as data
와 같이 불러왔는데, 이후에 동일한 이름인 data를 파일에서 읽어온 DataFrame 변수로 사용해서 생기는 네임스페이스 충돌 때문입니다.

예를 들어,

python
Copy code
data = load_data_from_txt("runwait.txt")
와 같이 사용하게 되면, 이후에

python
Copy code
train_dataset = data.TensorDataset(...)
를 호출할 때 data가 pandas DataFrame을 가리키므로, DataFrame에는 TensorDataset이라는 속성이 없다는 오류("no attribute")가 발생합니다.

해결방법
모듈과 변수 이름이 겹치지 않도록 변수명을 변경

torch 모듈은 그대로 사용하고, 파일에서 읽어온 데이터는 다른 이름(예: df_data 혹은 df)로 할당하세요.
코드 수정 예제

python
Copy code
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as tud  # torch의 데이터 관련 모듈은 tud와 같이 다른 이름으로 지정
import pandas as pd
import numpy as np
import pymssql
import os
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split

# GPU 설정 (가능한 경우 GPU 사용)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# TXT 파일에서 데이터 불러오기 함수
def load_data_from_txt(file_path):
    rows = []
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            parts = line.strip().split()
            if len(parts) >= 2:
                model_name, qr_value = parts[:2]
                rows.append((model_name, qr_value))
    return pd.DataFrame(rows, columns=["Model", "QR"])

# QR값 벡터화 함수
def vectorize_qr(qr_values):
    max_len = max(len(qr) for qr in qr_values)
    vectorized = np.zeros((len(qr_values), max_len), dtype=np.float32)
    for i, qr in enumerate(qr_values):
        for j, char in enumerate(qr):
            vectorized[i, j] = ord(char)  # 각 문자를 아스키 코드값으로 변환
    return vectorized

# 신경망 모델 정의
class QRModel(nn.Module):
    def __init__(self, input_size, num_classes):
        super(QRModel, self).__init__()
        self.fc1 = nn.Linear(input_size, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, 32)
        self.fc4 = nn.Linear(32, num_classes)  # 클래스 수 만큼 출력
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.relu(self.fc3(x))
        x = self.fc4(x)
        return x

# 모델 저장 및 불러오기 함수
MODEL_PATH = "model.pth"
def save_model(model, encoder, scaler):
    torch.save({
        "model_state_dict": model.state_dict(),
        "encoder_classes": encoder.classes_,
        "scaler_mean": scaler.mean_,
        "scaler_var": scaler.var_
    }, MODEL_PATH)

def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        # input_size는 저장된 scaler_mean의 길이로 판단
        input_size = len(checkpoint["scaler_mean"])
        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])
        
        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]
        
        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.var_ = checkpoint["scaler_var"]
        return model, encoder, scaler
    return None, None, None

# 학습 함수 (데이터 프레임을 인자로 받음)
def train_model(df_data, epochs=10, batch_size=64):
    qr_values = df_data["QR"].values
    model_names = df_data["Model"].values

    encoder = LabelEncoder()
    y_encoded = encoder.fit_transform(model_names)

    X_vectorized = vectorize_qr(qr_values)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    # 여기서 torch.utils.data를 tud로 사용합니다.
    train_dataset = tud.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                      torch.tensor(y_train, dtype=torch.long))
    train_loader = tud.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # 신경망 모델 생성 (출력 노드 수는 클래스 수)
    num_classes = len(encoder.classes_)
    model = QRModel(X_train.shape[1], num_classes).to(device)
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler)
    print("학습 완료 및 모델 저장!")

# 예측 함수
def predict_qr(qr_value):
    model, encoder, scaler = load_model()
    if model is None:
        print("학습된 모델이 없습니다. 먼저 모델을 학습하세요.")
        return
    
    model.eval()
    X_vectorized = vectorize_qr([qr_value])
    X_scaled = scaler.transform(X_vectorized)
    X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)

    with torch.no_grad():
        outputs = model(X_tensor)
        probabilities = torch.softmax(outputs, dim=1).cpu().numpy().squeeze()

    predicted_label = np.argmax(probabilities)
    predicted_model = encoder.inverse_transform([predicted_label])[0]
    confidence = probabilities[predicted_label] * 100

    print(f"예측된 모델: {predicted_model}, 신뢰도: {confidence:.2f}%")

# 실행 예제
if __name__ == "__main__":
    # 데이터 프레임 변수명을 df_data로 사용하여 torch 모듈과 충돌 방지
    df_data = load_data_from_txt("runwait.txt")
    train_model(df_data, epochs=20, batch_size=128)

    test_qr = "123ABC456"
    predict_qr(test_qr)
설명
네임스페이스 충돌 해결

import torch.utils.data as tud와 같이 모듈 이름을 바꾸어 사용합니다.
파일에서 불러온 데이터는 df_data와 같이 별도의 이름을 사용하여 모듈과 이름 충돌이 발생하지 않도록 합니다.
학습 및 예측 코드

데이터 전처리 후 TensorDataset을 사용해 학습 데이터를 구성하고 DataLoader를 만듭니다.