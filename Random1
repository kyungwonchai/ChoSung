녕하세요! 마크다운(.md) 파일과 이미지를 RAG(검색 증강 생성) 시스템에 학습시키기 위한 데이터로 변환하는 것은 아주 중요한 작업입니다. 에이전트가 정확하고 풍부한 답변을 생성하도록 하려면 텍스트와 이미지의 맥락을 모두 잘 살려야 합니다.

핵심 전략은 **"이미지를 텍스트로 변환하여 기존 마크다운 텍스트와 결합한 후, 의미 있는 단위로 나누어(Chunking) 데이터베이스에 저장"**하는 것입니다.

RAG 시스템은 기본적으로 텍스트 검색을 통해 관련 정보를 찾기 때문에, 이미지 자체를 직접 이해하기보다는 이미지에 대한 '설명'을 텍스트로 만들어주는 과정이 필수적입니다.

## 처리 프로세스 (단계별 가이드)
아래 4가지 단계를 거치면 효과적으로 데이터를 가공할 수 있습니다.

### 1단계: 마크다운 파싱 및 정보 추출
가장 먼저 .md 파일을 읽어와 텍스트 내용과 이미지 경로를 분리해야 합니다. 마크다운의 구조(제목, 목록 등)는 나중에 데이터를 의미 있는 단위로 나누는 데 중요한 단서가 되므로 유지하는 것이 좋습니다.

입력: ![강아지 이미지](images/dog.png) 라는 마크다운 텍스트

출력:

텍스트 부분: "강아지 이미지" (alt text)

이미지 경로: images/dog.png

### 2단계: 이미지 → 텍스트 변환 (가장 중요한 단계)
추출한 이미지 파일을 이미지 이해(Vision) AI 모델을 사용하여 상세한 텍스트로 설명합니다. 이 텍스트 설명이 RAG 시스템이 이미지를 '검색'할 수 있게 해주는 열쇠입니다.

사용 가능한 모델:

Google Gemini Pro Vision: 이미지에 대한 질문/답변 및 상세 묘사에 매우 뛰어납니다.

OpenAI GPT-4V(ision): 강력한 이미지 분석 및 설명 능력을 갖추고 있습니다.

오픈소스 모델: LLaVA, BLIP 등

예시:

입력 이미지: 공원에서 원반을 쫓는 골든 리트리버 사진

AI 모델 출력 (텍스트 설명): "밝은 햇살 아래 푸른 잔디밭이 있는 공원에서, 금색 털을 가진 골든 리트리버 한 마리가 공중으로 뛰어올라 빨간색 원반을 잡으려고 하고 있다. 개의 입은 살짝 벌어져 있고, 역동적인 자세를 취하고 있다."

### 3단계: 텍스트 결합 및 재구성
이제 원본 마크다운 텍스트에서 이미지 태그가 있던 위치에 방금 생성한 이미지 설명을 삽입합니다. 이렇게 하면 텍스트와 이미지의 맥락이 하나로 합쳐집니다.

변환 전:

Markdown

## 강아지의 하루
우리 집 강아지는 공원에서 노는 것을 가장 좋아합니다. 특히 원반 던지기를 즐깁니다.
![강아지 이미지](images/dog.png)
매일 오후 산책은 필수 코스입니다.
변환 후 (결합된 텍스트):

## 강아지의 하루
우리 집 강아지는 공원에서 노는 것을 가장 좋아합니다. 특히 원반 던지기를 즐깁니다.
[이미지 설명: 밝은 햇살 아래 푸른 잔디밭이 있는 공원에서, 금색 털을 가진 골든 리트리버 한 마리가 공중으로 뛰어올라 빨간색 원반을 잡으려고 하고 있다. 개의 입은 살짝 벌어져 있고, 역동적인 자세를 취하고 있다.]
매일 오후 산책은 필수 코스입니다.
### 4단계: 의미 기반 데이터 분할 (Semantic Chunking)
마지막으로, RAG가 효율적으로 검색할 수 있도록 재구성된 텍스트를 적절한 크기로 나눕니다. 단순히 글자 수로 나누기보다는 마크다운의 구조를 활용하는 것이 훨씬 효과적입니다.

좋은 분할 기준:

제목 단위: ##나 ### 같은 제목을 기준으로 문단을 나눕니다.

문단 단위: 내용의 흐름이 바뀌는 문단을 기준으로 나눕니다.

목록 단위: * 나 - 로 시작하는 목록 아이템별로 나눕니다.

이렇게 생성된 최종 텍스트 조각(Chunk)들을 임베딩하여 **벡터 데이터베이스(Vector DB)**에 저장하면 RAG 학습 데이터 준비가 완료됩니다.

## Python 코드 예시 (Gemini Vision API 활용)
아래는 특정 폴더에 있는 모든 .md 파일을 읽어 이미지를 텍스트로 변환하고, 원본 텍스트와 결합하여 새로운 파일로 저장하는 Python 스크립트 예시입니다.

사전 준비: 먼저 Google Gemini API를 사용할 수 있도록 라이브러리를 설치하고 API 키를 설정해야 합니다.

Bash

pip install -q -U google-generativeai
API 키는 Google AI Studio에서 발급받을 수 있습니다.

Python

import google.generativeai as genai
import os
import re
from pathlib import Path

# --------------------------------------------------------------------------
# 설정: 여기에 본인의 API 키와 작업 폴더 경로를 입력하세요.
# --------------------------------------------------------------------------
# API 키 설정 (환경 변수 사용을 권장)
# genai.configure(api_key=os.environ["GEMINI_API_KEY"])
genai.configure(api_key="YOUR_API_KEY_HERE")

# 원본 마크다운 파일이 있는 폴더
SOURCE_DIR = "./markdown_files"
# 이미지가 저장된 폴더 (마크다운 파일 기준 상대 경로)
IMAGE_BASE_DIR = os.path.join(SOURCE_DIR, "images")
# 결과 파일이 저장될 폴더
OUTPUT_DIR = "./processed_for_rag"
# --------------------------------------------------------------------------

# Gemini Pro Vision 모델 설정
vision_model = genai.GenerativeModel('gemini-pro-vision')

def generate_image_description(image_path):
    """주어진 이미지 경로를 바탕으로 Gemini를 이용해 상세한 설명을 생성합니다."""
    if not os.path.exists(image_path):
        return f"[오류: 이미지를 찾을 수 없습니다 - {image_path}]"
    
    try:
        print(f"이미지 처리 중: {image_path}")
        image_part = {
            'mime_type': 'image/jpeg', # 이미지 타입에 맞게 변경 (png, webp 등)
            'data': Path(image_path).read_bytes()
        }
        
        # 프롬프트: 이미지에 대해 상세하고 객관적인 설명을 요청
        prompt = "Describe this image in detail for a knowledge base. Be objective and focus on the key elements, actions, and setting."
        
        response = vision_model.generate_content([prompt, image_part])
        return response.text.strip()
    except Exception as e:
        return f"[오류: 이미지 설명 생성 실패 - {e}]"

def process_markdown_file(file_path):
    """마크다운 파일을 읽어 이미지 태그를 텍스트 설명으로 변환합니다."""
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()

    # 마크다운 이미지 태그를 찾는 정규식: ![alt_text](image_path)
    image_pattern = re.compile(r'!\[(.*?)\]\((.*?)\)')
    
    matches = list(image_pattern.finditer(content))
    
    # 수정된 내용을 저장하기 위해 원본 내용을 복사
    new_content = content
    
    for match in reversed(matches): # 뒤에서부터 치환해야 인덱스가 꼬이지 않음
        alt_text = match.group(1)
        image_relative_path = match.group(2)
        
        # 마크다운 파일의 위치를 기준으로 이미지의 전체 경로를 계산
        image_full_path = os.path.abspath(os.path.join(os.path.dirname(file_path), image_relative_path))
        
        # 이미지 설명 생성
        description = generate_image_description(image_full_path)
        
        # 생성된 설명으로 이미지 태그를 교체
        replacement_text = f"\n[이미지 설명: {description}]\n"
        
        # 원본 내용에서 해당 이미지 태그 부분을 교체
        start, end = match.span()
        new_content = new_content[:start] + replacement_text + new_content[end:]

    return new_content

def main():
    """지정된 폴더의 모든 마크다운 파일을 처리합니다."""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)

    for filename in os.listdir(SOURCE_DIR):
        if filename.endswith(".md"):
            source_file_path = os.path.join(SOURCE_DIR, filename)
            output_file_path = os.path.join(OUTPUT_DIR, filename)
            
            print(f"파일 처리 시작: {source_file_path}")
            processed_content = process_markdown_file(source_file_path)
            
            with open(output_file_path, 'w', encoding='utf-8') as f:
                f.write(processed_content)
            
            print(f"처리 완료 및 저장: {output_file_path}\n")

if __name__ == "__main__":
    main()
이 스크립트를 실행하면 OUTPUT_DIR에 원본 마크다운 파일의 이미지 링크들이 모두 상세한 텍스트 설명으로 대체된 새로운 파일들이 생성됩니다. 이 파일들을 다음 단계인 Chunking 및 임베딩 과정에 사용하시면 됩니다.






Deep Research
