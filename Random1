    model.eval()
    predictions = []
    with torch.no_grad():
        for texts, _, lengths in test_loader:
            texts, lengths = texts.to(device), lengths.to(device)
            outputs = model(texts, lengths)
            _, preds = torch.max(outputs, 1)
            predictions.extend(preds.cpu().numpy())

    # 예측 결과 저장
    decoded_predictions = train_dataset.label_encoder.inverse_transform(predictions)
    results_file = os.path.join(data_dir, "prediction_results.txt")

    with open(results_file, 'w', encoding='utf-8') as f:
        for file_path, pred_label in zip(test_file_paths, decoded_predictions):
            actual_label = os.path.splitext(os.path.basename(file_path))[0]  # 실제 파일명
            f.write(f"{actual_label} -> {pred_label}\n")

    print(f"? 예측 결과 저장 완료: {results_file}")
    
if __name__ == "__main__":
    data_directory = "./data"  # 데이터셋 폴더 경로 (텍스트 파일이 위치한 디렉토리)
    main(data_directory)
