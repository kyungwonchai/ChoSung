RAG 시스템에서 부품 코드와 그 설명을 효과적으로 검색하고 답변을 생성하기 위한 청크 설정은 매우 중요합니다. 현재 부품 코드를 물어봐도 전혀 모른다고 나오는 문제는 청크가 제대로 구성되지 않아 검색 단계에서 관련 정보를 찾지 못하기 때문일 가능성이 큽니다.

다음은 청크 설정을 위한 몇 가지 전략과 고려 사항입니다.

핵심 원칙: 부품 코드와 설명은 하나의 단위로 묶여야 합니다.

가장 중요한 것은 부품 코드와 해당 설명이 의미적으로 연결된 최소 단위라는 점입니다. 따라서 청크를 나눌 때 이 둘이 분리되지 않도록 하는 것이 핵심입니다.

추천 청크 전략:

"하나의 부품 = 하나의 청크" 전략:

설정: 각 부품 코드와 그에 해당하는 전체 설명을 하나의 청크로 만듭니다.
예시 청크 내용:
부품코드: 12345678901
설명: 이 부품은 자동차 엔진의 핵심 부품으로, 고온 고압 환경에서도 견딜 수 있도록 특수 합금으로 제작되었습니다. 주요 기능은 연료와 공기의 혼합물을 압축하고 폭발시켜 동력을 생성하는 것입니다. 정기적인 점검과 교체가 필요하며, 권장 교체 주기는 5만 km입니다.
청크 크기 설정: 이 경우, chunk_size는 사실상 각 "부품 코드 + 설명"의 전체 길이가 됩니다. 대부분의 RAG 라이브러리(예: LangChain)는 텍스트 자체를 기준으로 청크를 나누기 때문에, 데이터를 사전 처리하여 각 부품 정보가 한 덩어리가 되도록 만들어야 합니다.
장점:
부품 코드와 설명이 항상 함께 검색되므로 정보 누락이 없습니다.
의미론적으로 가장 정확한 단위입니다.
단점:
설명이 매우 긴 경우, 하나의 청크가 너무 커져서 임베딩 모델의 컨텍스트 길이 제한을 초과하거나 LLM에 전달할 때 문제가 될 수 있습니다. (일반적으로 임베딩 모델은 512 토큰 ~ 수천 토큰, LLM은 수천 토큰 ~ 수십만 토큰의 컨텍스트 길이를 가집니다.)
설명이 매우 긴 경우: "부품 코드 반복 + 설명 분할" 전략:

만약 한 부품의 설명이 너무 길어서 임베딩 모델의 토큰 제한을 초과하거나, LLM 컨텍스트에 부담을 준다면, 설명을 의미 있는 단위로 나누되 각 분할된 설명 청크의 시작 부분에 해당 부품 코드를 반복해서 넣어줍니다.
예시 (설명이 매우 긴 경우):
원본 데이터:
부품코드: ABCDEFGHIJK
설명: (매우 긴 설명 첫 부분)...(매우 긴 설명 중간 부분)...(매우 긴 설명 마지막 부분)
분할된 청크 예시 (chunk_size를 특정 토큰 수, 예를 들어 500 토큰으로 설정하고 chunk_overlap을 50~100 토큰 정도로 설정):
청크 1:
부품코드: ABCDEFGHIJK
설명: (매우 긴 설명 첫 부분)...
청크 2:
부품코드: ABCDEFGHIJK
설명: ...(첫 부분과 겹치는 일부)...(매우 긴 설명 중간 부분)...
청크 3:
부품코드: ABCDEFGHIJK
설명: ...(중간 부분과 겹치는 일부)...(매우 긴 설명 마지막 부분)
장점:
긴 설명도 처리할 수 있습니다.
각 청크에 부품 코드가 포함되어 있어 검색 정확도를 유지할 수 있습니다.
단점:
데이터 전처리가 좀 더 복잡해집니다.
부품 코드가 중복 저장됩니다 (저장 공간 측면에서는 미미한 단점).
chunk_size 설정 숫자: 일반적으로 임베딩 모델의 컨텍스트 길이를 고려하여 설정합니다. (예: 512, 1000 토큰). 문자 수 기준으로는 대략 한글 1글자당 2~3토큰으로 어림잡을 수 있지만, 정확한 것은 사용하는 토크나이저로 확인해야 합니다.
chunk_overlap 설정 숫자: chunk_size의 10~20% 정도를 설정하여 문맥이 끊어지는 것을 방지합니다. (예: chunk_size가 500이면 chunk_overlap은 50~100).
"전혀 몰라요" 문제 해결을 위한 추가 팁:

메타데이터 활용: 청크를 생성할 때, 각 청크의 메타데이터(metadata)에 부품코드를 명시적으로 저장하는 것이 매우 효과적입니다.
예: {'source': '부품매뉴얼_v2.txt', 'part_code': '12345678901', 'page': 3}
이렇게 하면 벡터 검색 후, 검색된 청크들의 메타데이터에서 부품 코드를 확인하거나, 검색 시 메타데이터 필터링(예: "부품코드가 '12345678901'인 청크만 검색")을 사용할 수 있습니다.
전처리: 데이터를 로드할 때 "첫째 행: 부품코드, 둘째 행: 설명" 구조를 파싱하여 위에서 제안한 청크 형태로 재구성하는 스크립트를 작성해야 합니다.
예를 들어, 두 줄을 읽어 하나의 문자열로 합치되, "부품코드: [코드]\n설명: [설명]" 형태로 만듭니다.
임베딩: 부품 코드 자체도 텍스트의 일부로 포함하여 임베딩해야 합니다. 이렇게 하면 "12345678901 찾아줘" 같은 질문에 대해 부품 코드가 포함된 청크가 더 잘 검색될 수 있습니다.
질의 형식: 사용자가 "부품코드 11122233344에 대해 알려줘"라고 질문했을 때, 이 질문 자체를 임베딩하여 유사한 청크를 찾게 됩니다. 만약 청크에 부품 코드가 명확히 포함되어 있다면 검색될 확률이 높아집니다.
어떤 청크 크기 숫자를 사용해야 하나요?

전략 1 ("하나의 부품 = 하나의 청크")을 따른다면: chunk_size를 매우 크게 설정하거나, 아예 청크 분할 기능을 사용하지 않고 직접 각 부품 정보를 하나의 문서(청크)로 만들어 리스트로 제공하는 방식을 사용합니다. 이 경우, 평균적인 "부품코드+설명"의 토큰 길이를 확인하고, 사용하는 임베딩 모델과 LLM의 컨텍스트 제한을 넘지 않는지 확인해야 합니다.
전략 2 ("부품 코드 반복 + 설명 분할")을 따른다면:
chunk_size: 사용하려는 임베딩 모델의 권장 토큰 수 (예: 많은 모델이 512 토큰을 기준으로 합니다) 또는 약간 더 크게 (예: 1000~2000 토큰) 설정할 수 있습니다. 너무 작으면 문맥이 부족하고, 너무 크면 특정 정보의 밀도가 낮아질 수 있습니다.
chunk_overlap: chunk_size의 10-20% (예: chunk_size가 1000이면 100-200)로 설정합니다.
가장 먼저 시도해볼 것:

데이터 전처리: 각 부품 코드와 설명을 "부품코드: [코드]\n설명: [설명]" 형태의 문자열로 합쳐서 하나의 단위로 만드세요.
청킹: 이렇게 합쳐진 문자열 각각을 하나의 청크로 간주하고 RAG 시스템에 넣어보세요. (즉, chunk_size를 이 합쳐진 문자열의 길이보다 크게 설정하거나, 청크 분할을 적용하지 않음).