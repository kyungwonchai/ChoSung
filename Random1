습니다. commandqueue 로그를 메인으로 유지하면서, 나머지 파일들은 시간과 로그 값을 SentValue 컬럼에 통합하여 하나로 묶는 방식으로 수정하겠습니다. 또한, A 열에는 파일명을 넣어 로그가 어떤 파일에서 왔는지 알 수 있도록 하겠습니다.

아래는 수정된 코드입니다:

python
코드 복사
import os
import csv
from datetime import datetime

# Log file directory
log_directory = "c:/test"

# Dictionary to store unique SentValue prefixes for commandqueue logs
unique_prefixes = {}

# List to store the parsed log data for both commandqueue and other logs
log_data = []

# Process commandqueue files
for filename in os.listdir(log_directory):
    if filename.endswith(".txt") and "commandqueue" in filename.lower():
        file_path = os.path.join(log_directory, filename)
        
        # Open and read the file once
        with open(file_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            for line in lines:
                # Split the line by '|'
                parts = line.strip().split('|')
                if len(parts) == 7:  # Only process if all required fields are present
                    # Extract the first 14 characters of SentValue as a prefix
                    prefix = parts[1][:14]
                    unique_prefixes[prefix] = None  # Store as a key for uniqueness
                    
                    # Extract response value based on conditions
                    response_value = parts[2]
                    if "WDD" in prefix:
                        sent_value = parts[1]
                        extracted_value = sent_value[19:] if len(sent_value) >= 20 else ""
                    else:
                        extracted_value = response_value[-7:] if len(response_value) >= 7 else response_value
                    
                    # Remove the last 2 characters from the extracted value
                    extracted_value = extracted_value[:-2] if len(extracted_value) > 2 else ""
                    
                    # Add the row to the log data list
                    log_data.append([filename, parts[0], parts[1], parts[2], parts[3], parts[4], parts[5], parts[6], prefix, extracted_value])

# Process other .txt files (non-commandqueue files)
for filename in os.listdir(log_directory):
    if filename.endswith(".txt") and "commandqueue" not in filename.lower():
        file_path = os.path.join(log_directory, filename)
        
        # Open and read the file once, process all lines at once
        with open(file_path, 'r', encoding='utf-8') as file:
            lines = file.readlines()
            for line in lines:
                # Extract time value enclosed in [] and the remaining part as SentValue
                if '[' in line and ']' in line:
                    start_idx = line.index('[')
                    end_idx = line.index(']', start_idx) + 1
                    time_value = line[start_idx:end_idx]  # Extract the time value with brackets
                    remaining_value = line[end_idx:].strip()  # Remaining part of the line as SentValue
                    
                    # Add a row for non-commandqueue logs, filling other columns as empty
                    log_data.append([filename, time_value, remaining_value, "", "", "", "", "", "", ""])

# Sort the log data by the time value
log_data.sort(key=lambda x: x[1])

# Convert unique prefixes from commandqueue into a sorted list
sorted_prefixes = sorted(unique_prefixes.keys())

# Prepare the output directory
output_directory = "c:/test/csv2"
os.makedirs(output_directory, exist_ok=True)

# Create the output file name with the current timestamp
timestamp = datetime.now().strftime("%Y%m%d%H%M%S")
output_file = os.path.join(output_directory, f"{timestamp}_merged_log_output.csv")

# Save the sorted data to a CSV file with dynamic columns based on SentValue prefixes
with open(output_file, 'w', newline='', encoding='utf-8-sig') as csvfile:
    csvwriter = csv.writer(csvfile)
    
    # Write column headers
    headers = ["FileName", "Time", "SentValue", "ResponseValue", "Result", "Result2", "Retry", "Speed"] + sorted_prefixes + ["ExtractedValue"]
    csvwriter.writerow(headers)
    
    # Write all the data at once, ensuring that commandqueue logs and others are handled properly
    for row in log_data:
        if "commandqueue" in row[0].lower():
            # For commandqueue, maintain the structure and fill in the appropriate columns
            data_row = row[:8]  # Base columns
            prefix_values = [''] * len(sorted_prefixes)
            prefix = row[8]
            if prefix in sorted_prefixes:
                prefix_index = sorted_prefixes.index(prefix)
                prefix_values[prefix_index] = f"'{row[9]}"  # Add extracted value as text
            csvwriter.writerow(data_row + prefix_values + [row[9]])
        else:
            # For non-commandqueue, leave commandqueue-specific columns empty and use only filename, time, and combined value
            data_row = row[:3] + [""] * 5  # Fill only FileName, Time, and SentValue, others empty
            prefix_values = [''] * len(sorted_prefixes)
            csvwriter.writerow(data_row + prefix_values + [""])

print(f"CSV file has been saved as '{output_file}'.")
코드 설명
commandqueue 로그 처리: