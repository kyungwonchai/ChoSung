맞습니다! 데이터가 Test와 Real로 나누어져 있다면, 이를 적절히 훈련과 검증에 사용하는 것이 중요합니다.

여기서 선택할 수 있는 접근 방식은 다음과 같습니다:

1. 데이터 분리 방안
(1) Train/Test 분리
Test 데이터를 훈련(train) 데이터로 사용하고, Real 데이터를 검증(test) 데이터로 사용.
이 방식은 간단하며, Real 데이터는 오직 검증 목적으로만 사용됩니다.
(2) 교차 검증 (K-Fold Cross-Validation)
Test 데이터를 K개의 폴드로 나누고, 교차 검증을 통해 훈련과 검증을 반복 수행.
Real 데이터는 최종 평가 단계에서 사용.
이 방식은 데이터의 일반화 성능을 평가하는 데 유용합니다.
2. 하나의 방식을 선택할 경우
간단한 Train/Test 분리로 진행
Test 데이터를 훈련에 사용하고, Real 데이터를 검증에 사용하는 방식으로 진행하겠습니다.

3. 수정된 전체 코드
python
코드 복사
import numpy as np
import pandas as pd
import pymssql
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error
import matplotlib.pyplot as plt
from tqdm import tqdm


# 1. 데이터베이스에서 데이터 가져오기 함수
def fetch_data_from_procedure_with_cursor(proc_name, connection_details):
    """
    MSSQL 저장 프로시저를 호출하여 데이터를 가져오는 함수.
    커서를 사용하여 결과를 Pandas DataFrame으로 반환.
    
    :param proc_name: 저장 프로시저 이름 (str).
    :param connection_details: 데이터베이스 연결 정보 (dict).
    :return: Pandas DataFrame.
    """
    print(f"Calling stored procedure: {proc_name}")
    try:
        # 데이터베이스 연결
        conn = pymssql.connect(
            server=connection_details['server'],
            user=connection_details['user'],
            password=connection_details['password'],
            database=connection_details['database']
        )
        cursor = conn.cursor()

        # 저장 프로시저 실행
        cursor.execute(f"EXEC {proc_name}")

        # 결과를 DataFrame으로 변환
        columns = [desc[0] for desc in cursor.description]
        data = cursor.fetchall()
        df = pd.DataFrame(data, columns=columns)

        print(f"Data successfully fetched from procedure: {proc_name}")
        return df

    except Exception as e:
        print(f"Error while calling procedure {proc_name}: {e}")
        return pd.DataFrame()

    finally:
        conn.close()


# 2. DB 연결 정보
connection_details = {
    "server": "localhost",
    "user": "your_username",
    "password": "your_password",
    "database": "your_database"
}

# 3. 데이터 가져오기
print("Fetching data from stored procedures...")
df_test_a = fetch_data_from_procedure_with_cursor("PTestA", connection_details)
df_test_b = fetch_data_from_procedure_with_cursor("PTestB", connection_details)
df_real_a = fetch_data_from_procedure_with_cursor("PRealA", connection_details)
df_real_b = fetch_data_from_procedure_with_cursor("PRealB", connection_details)

# 4. 데이터 준비
if df_test_a.empty or df_test_b.empty or df_real_a.empty or df_real_b.empty:
    print("Error: One or more datasets are empty. Check the stored procedures.")
    exit()

# 데이터에서 첫 열(날짜/시간)을 제외한 나머지 값만 추출
data_a_train = df_test_a.iloc[:, 1:].values
data_b_train = df_test_b.iloc[:, 1:].values
data_a_test = df_real_a.iloc[:, 1:].values
data_b_test = df_real_b.iloc[:, 1:].values

# 5. 모델 리스트 정의
models = {
    "RandomForest": RandomForestRegressor(),
    "LinearRegression": LinearRegression(),
    "SVR": SVR(kernel="linear")
}

# 6. 데이터 A 학습 및 검증
print("Starting model training for data_a...")
best_models_a = []
errors_a = []

for i in tqdm(range(data_a_train.shape[1]), desc="Training models for data_a"):
    try:
        # i번째 값을 제외한 나머지 데이터로 학습 데이터 구성
        X_a_train = np.delete(data_a_train, i, axis=1)  # i번째 열을 제외
        y_a_train = data_a_train[:, i]  # 예측 대상

        X_a_test = np.delete(data_a_test, i, axis=1)  # 테스트 데이터의 i번째 열 제외
        y_a_test = data_a_test[:, i]  # 테스트 데이터의 예측 대상

        # 각 모델로 학습 및 평가
        best_model = None
        best_error = float("inf")
        for model_name, model in models.items():
            model.fit(X_a_train, y_a_train)  # 학습
            predictions = model.predict(X_a_test)  # 검증
            error = mean_squared_error(y_a_test, predictions)  # MSE 계산

            print(f"Model: {model_name}, MSE: {error:.5f}")
            if error < best_error:
                best_error = error
                best_model = model_name

        best_models_a.append((best_model, models[best_model]))
        errors_a.append(best_error)

    except Exception as e:
        print(f"Error during training for data_a column {i}: {e}")
        raise

# 7. 데이터 B 학습 및 검증
print("Starting model training for data_b...")
best_models_b = []
errors_b = []

for i in tqdm(range(data_b_train.shape[1]), desc="Training models for data_b"):
    try:
        # i번째 값을 제외한 나머지 데이터로 학습 데이터 구성
        X_b_train = np.delete(data_b_train, i, axis=1)  # i번째 열을 제외
        y_b_train = data_b_train[:, i]  # 예측 대상

        X_b_test = np.delete(data_b_test, i, axis=1)  # 테스트 데이터의 i번째 열 제외
        y_b_test = data_b_test[:, i]  # 테스트 데이터의 예측 대상

        # 각 모델로 학습 및 평가
        best_model = None
        best_error = float("inf")
        for model_name, model in models.items():
            model.fit(X_b_train, y_b_train)  # 학습
            predictions = model.predict(X_b_test)  # 검증
            error = mean_squared_error(y_b_test, predictions)  # MSE 계산

            print(f"Model: {model_name}, MSE: {error:.5f}")
            if error < best_error:
                best_error = error
                best_model = model_name

        best_models_b.append((best_model, models[best_model]))
        errors_b.append(best_error)

    except Exception as e:
        print(f"Error during training for data_b column {i}: {e}")
        raise

# 8. 결과 출력
print("Training completed.")
print("Data A models:", best_models_a)
print("Data B models:", best_models_b)
주요 변경 사항
Train/Test 분리

Test 데이터를 data_a_train과 data_b_train으로 학습에 사용.
Real 데이터를 data_a_test와 data_b_test로 검증에 사용.
훈련과 검증의 분리

np.delete를 사용하여 각 열(i)을 예측 대상으로 제외하고 나머지 데이터를 입력으로 사용.
평가 지표

각 모델의 검증 데이터에 대한 MSE(Mean Squared Error)를 계산하여 최적 모델 선택.
결과 예시
data_a 학습:
plaintext
코드 복사
Training models for data_a: 100%|██████████| 4/4 [00:10<00:00,  2.5s/it]
data_b 학습:
plaintext
코드 복사
Training models for data_b: 100%|██████████| 5/5 [00:12<00:00,  2.4s/it]
최종 출력:
plaintext
코드 복사
Training completed.
Data A models: [('RandomForest', RandomForestRegressor()), ...]
Data B models: [('LinearRegression', LinearRegression()), ...]
추가 고려 사항
교차 검증(K-Fold)

더 높은 일반화 성능 평가가 필요하면 교차 검증(K-Fold)을 도입할 수 있습니다.
실시간 예측
