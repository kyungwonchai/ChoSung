ìœ ì§€í•˜ë©´ì„œ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€ í•™ìŠµí•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•´ì¤€ë‹¤.

ğŸ“Œ ê¸°ì¡´ ëª¨ë¸ + ìƒˆë¡œìš´ ë°ì´í„° ì¶”ê°€ í•™ìŠµ ë°©ë²•
âœ… ê¸°ì¡´ ëª¨ë¸ì„ ìœ ì§€í•˜ê³  ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•™ìŠµ
âœ… ê¸°ì¡´ ê°€ì¤‘ì¹˜ë¥¼ ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ ì¶”ê°€ í•™ìŠµ ì§„í–‰
âœ… ìƒˆ ë°ì´í„°ë¥¼ ë°˜ì˜í•œ í›„ ê¸°ì¡´ ëª¨ë¸ì„ ë®ì–´ì“°ê¸°

âœ… 1. ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° (load_model)
ë¨¼ì €, ê¸°ì¡´ ëª¨ë¸(model.pth)ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê³ , ì—†ìœ¼ë©´ ìƒˆë¡œìš´ ëª¨ë¸ì„ í•™ìŠµí•´ì•¼ í•œë‹¤.

python
Copy code
def load_model():
    if os.path.exists(MODEL_PATH):
        checkpoint = torch.load(MODEL_PATH, map_location=device)
        num_classes = len(checkpoint["encoder_classes"])
        input_size = len(checkpoint["scaler_mean"])

        model = QRModel(input_size, num_classes).to(device)
        model.load_state_dict(checkpoint["model_state_dict"])  # ê¸°ì¡´ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        model.train()  # ğŸ”¥ ì¶”ê°€ í•™ìŠµì„ ìœ„í•´ train ëª¨ë“œ

        encoder = LabelEncoder()
        encoder.classes_ = checkpoint["encoder_classes"]

        scaler = StandardScaler()
        scaler.mean_ = checkpoint["scaler_mean"]
        scaler.scale_ = checkpoint["scaler_scale"]

        max_qr_length = checkpoint["max_qr_length"]

        return model, encoder, scaler, max_qr_length
    return None, None, None, None
âœ… 2. ê¸°ì¡´ ëª¨ë¸ê³¼ ìƒˆë¡œìš´ ë°ì´í„°ë¡œ ì¶”ê°€ í•™ìŠµ (train_model)
ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë¡œë“œ
ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€ í•™ìŠµ
í•™ìŠµ í›„ ê¸°ì¡´ ëª¨ë¸ ë®ì–´ì“°ê¸°
python
Copy code
def train_model(new_df_data, epochs=10, batch_size=64):
    new_df_data = filter_recent_data(new_df_data)  # ğŸ”¥ 3ê°œì›” ì§€ë‚œ ë°ì´í„° ì œì™¸

    # ê¸°ì¡´ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°
    model, encoder, scaler, max_qr_length = load_model()

    if model is None:
        print("ğŸ”´ ê¸°ì¡´ ëª¨ë¸ ì—†ìŒ. ìƒˆë¡œ í•™ìŠµ ì‹œì‘.")
        encoder = LabelEncoder()
        full_df_data = new_df_data  # ìƒˆ ë°ì´í„°ë§Œ í•™ìŠµ
    else:
        print("ğŸŸ¢ ê¸°ì¡´ ëª¨ë¸ ë¡œë“œë¨. ì¶”ê°€ í•™ìŠµ ì§„í–‰.")
        full_df_data = new_df_data  # ğŸ”¥ ê¸°ì¡´ ë°ì´í„° í•„ìš” ì—†ì´ ìƒˆ ë°ì´í„°ë§Œ í•™ìŠµ

    # QR ê°’, ëª¨ë¸ëª… ì¶”ì¶œ
    qr_values = full_df_data["QR"].values
    model_names = full_df_data["Model"].values

    y_encoded = encoder.fit_transform(model_names)

    max_qr_length = max(len(qr) for qr in qr_values)
    X_vectorized = vectorize_qr(qr_values, max_qr_length)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_vectorized)

    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)

    train_dataset = data_utils.TensorDataset(torch.tensor(X_train, dtype=torch.float32),
                                             torch.tensor(y_train, dtype=torch.long))
    train_loader = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

    # ê¸°ì¡´ ëª¨ë¸ì´ ìˆìœ¼ë©´ ì¶”ê°€ í•™ìŠµ
    if model is None:
        num_classes = len(encoder.classes_)
        model = QRModel(X_train.shape[1], num_classes).to(device)
    else:
        num_classes = len(encoder.classes_)
        model.fc4 = nn.Linear(32, num_classes).to(device)  # ìƒˆë¡œìš´ í´ë˜ìŠ¤ ë°˜ì˜

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # ğŸ”¥ ì¶”ê°€ í•™ìŠµ ì§„í–‰
    model.train()
    for epoch in range(epochs):
        total_loss = 0
        for inputs, targets in train_loader:
            inputs, targets = inputs.to(device), targets.to(device)
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, targets)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()

        print(f"Epoch [{epoch+1}/{epochs}], Loss: {total_loss/len(train_loader):.4f}")

    save_model(model, encoder, scaler, max_qr_length)
    print("ğŸ‰ ì¶”ê°€ í•™ìŠµ ì™„ë£Œ! ëª¨ë¸ ì—…ë°ì´íŠ¸ë¨.")
âœ… 3. ì¶”ê°€ í•™ìŠµ ì‹¤í–‰
ì´ì œ ìƒˆë¡œìš´ ë°ì´í„°ë§Œ ì¶”ê°€ í•™ìŠµí•  ìˆ˜ ìˆë‹¤.

python
Copy code
if __name__ == "__main__":
    new_df_data = load_data_from_txt("runwait.txt")  # ğŸ”¥ ìƒˆë¡œìš´ ë°ì´í„° ê°€ì ¸ì˜´
    train_model(new_df_data, epochs=20, batch_size=128)  # ê¸°ì¡´ ëª¨ë¸ì— ì¶”ê°€ í•™ìŠµ
    test_qr = "123ABC456"  # ì˜ˆì¸¡í•  QR ê°’
    predict_qr(test_qr)  # ì˜ˆì¸¡ ì‹¤í–‰
ğŸ“Œ ìµœì¢… ì •ë¦¬ (100% ì¶”ê°€ í•™ìŠµ ê°€ëŠ¥)
âœ… ì¶”ê°€ í•™ìŠµ ë¡œì§
ê¸°ì¡´ ëª¨ë¸(model.pth)ì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì˜¤ê¸°
ìƒˆë¡œìš´ ë°ì´í„°ë§Œ í•™ìŠµ
ê¸°ì¡´ ëª¨ë¸ ê°€ì¤‘ì¹˜ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ í•™ìŠµ ì§„í–‰
í•™ìŠµ í›„ ê¸°ì¡´ ëª¨ë¸ ì—…ë°ì´íŠ¸ (save_model)
ìƒˆ ëª¨ë¸ë¡œ ì˜ˆì¸¡ ê°€ëŠ¥
ì´ì œ ê¸°ì¡´ ëª¨ë¸ì„ ìœ ì§€í•˜ë©´ì„œ ì¶”ê°€ ë°ì´í„°ë¡œ í•™ìŠµí•  ìˆ˜ ìˆë‹¤. ğŸš€ ì´ì œ ëŒë ¤ì„œ í…ŒìŠ¤íŠ¸í•˜ë©´ ëœë‹¤!











Search


ChatGPT can make mistakes. Check important info.