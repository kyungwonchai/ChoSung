하는 예시 코드입니다.

python

import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.externals import joblib
from Levenshtein import distance

def preprocess_data(data):
    # 데이터 전처리 작업 수행 (예: 특수문자 제거, 소문자 변환 등)
    preprocessed_data = ...

    return preprocessed_data

def train_model(data):
    # 데이터 전처리
    preprocessed_data = preprocess_data(data)

    # 벡터 변환
    vectorizer = CountVectorizer()
    parts_vector = vectorizer.fit_transform(preprocessed_data)

    # 유사도 계산
    similarity_matrix = cosine_similarity(parts_vector)

    return similarity_matrix, vectorizer

def save_model(similarity_matrix, vectorizer, model_file, vectorizer_file):
    # 모델 저장
    joblib.dump(similarity_matrix, model_file)
    joblib.dump(vectorizer, vectorizer_file)

# mssql로부터 데이터 가져오기
data = ...

# 모델 학습
similarity_matrix, vectorizer = train_model(data)

# 학습된 모델 저장
save_model(similarity_matrix, vectorizer, 'model.pkl', 'vectorizer.pkl')

위의 코드에서 preprocess_data() 함수는 데이터 전처리를 수행하는 부분입니다. 데이터에 대해 필요한 전처리 작업을 수행하여 적절한 형태로 가공해야 합니다.

train_model() 함수는 데이터를 전처리하고, 벡터 변환을 수행하며, 유사도를 계산하여 유사도 행렬을 반환합니다.

save_model() 함수는 학습된 모델과 벡터 변환기를 저장하는 역할을 합니다. similarity_matrix와 vectorizer를 파일로 저장하여 나중에 불러와 사용할 수 있습니다.

이제 모델을 불러와 검색을 수행하는 과정을 살펴보겠습니다.

python

import pandas as pd
from sklearn.externals import joblib
from Levenshtein import distance

def load_model(model_file, vectorizer_file):
    # 모델 로드
    similarity_matrix = joblib.load(model_file)
    vectorizer = joblib.load(vectorizer_file)

    return similarity_matrix, vectorizer

def find_similar_parts(input_text, similarity_matrix, vectorizer, parts_data):
    # 입력된 텍스트와 각 부품코드의 유사도 계산
    input_vector = vectorizer.transform([input_text])
    similarity_scores = cosine_similarity(input_vector, similarity_matrix).flatten()

    # 유사도가 가장 높은 순서대로 정렬하여 상위 10개 부품코드 추출
    top_indices = similarity

User
이어서
ChatGPT

indices.argsort()[:-11:-1]
similar_parts = parts_data[top_indices]

python

# Levenshtein 거리를 계산하여 가장 유사한 순서로 정렬
similarity_scores = [distance(input_text, part) for part in similar_parts]
similar_parts_with_distance = sorted(zip(similarity_scores, similar_parts))

return similar_parts_with_distance

저장된 모델과 데이터 로드

similarity_matrix, vectorizer = load_model('model.pkl', 'vectorizer.pkl')
parts_data = pd.read_csv('부품코드.csv')['부품코드'].values
사용자 입력 받기

input_text = input("부품코드를 입력하세요: ")
유사한 부품코드 검색

similar_parts = find_similar_parts(input_text, similarity_matrix, vectorizer, parts_data)
결과 출력

for distance, part in similar_parts:
print(f'{part}: {distance}')

go


위의 코드에서 `load_model()` 함수는 저장된 모델과 벡터 변환기를 로드합니다. `model_file`과 `vectorizer_file`은 이전에 저장한 파일의 경로입니다.

`find_similar_parts()` 함수는 입력된 텍스트와 유사한 부품코드를 검색하는 과정을 나타냅니다. 입력 텍스트를 벡터로 변환하고, 유사도를 계산하여 상위 10개의 부품코드를 추출한 후, Levenshtein 거리를 계산하여 유사도 순서로 정렬한 결과를 반환합니다.

위의 코드를 참고하여 데이터를 가져