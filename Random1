import pymssql
import csv
import re
from datetime import datetime, timedelta
from collections import Counter
import matplotlib.pyplot as plt

# 데이터베이스 연결 정보
server = '192.168.1.100'
user = 'sa'
password = 'mypassword123'
database = 'NPM_DAS_DATAS'

# MSSQL 데이터베이스 연결 (포트 5555로 설정)
conn = pymssql.connect(server=server, user=user, password=password, database=database, port=5555)
cursor = conn.cursor()

# LOG로 시작하는 모든 테이블 이름 가져오기
cursor.execute("""
    SELECT TABLE_NAME
    FROM INFORMATION_SCHEMA.TABLES
    WHERE TABLE_NAME LIKE 'LOG%'
""")

tables = cursor.fetchall()
pattern = re.compile(r'Reel ID=([^\s]+)')

# 결과를 저장할 리스트 초기화
result_rows = []

# 각 테이블에서 log1 컬럼 값이 'splicing'인 행 찾기
partid_list = []
for table in tables:
    table_name = table[0]
    query = f"SELECT line1, machine1, lane1, log1, log2, datatime1 FROM {table_name} WHERE log1 = 'splicing'"
    cursor.execute(query)
    rows = cursor.fetchall()

    for row in rows:
        line1, machine1, lane1, log1, log2, datatime1 = row
        
        # `partid` 추출
        partid_match = pattern.search(log2)
        partid = partid_match.group(1) if partid_match else None
        partid_list.append(partid)
        
        # 날짜와 시간에 따른 date1과 shift1 계산 (7시 이상 19시 이하이면 day, 그 외는 night)
        datatime = datetime.strptime(str(datatime1), '%Y-%m-%d %H:%M:%S')
        if datatime.hour < 7:
            date1 = (datatime - timedelta(days=1)).strftime('%Y-%m-%d')
        else:
            date1 = datatime.strftime('%Y-%m-%d')
        
        # shift1 계산
        if 7 <= datatime.hour < 19:
            shift1 = 'day'
        else:
            shift1 = 'night'

        # 결과 리스트에 추가
        result_rows.append([line1, machine1, lane1, log1, log2, partid, date1, shift1, datatime1])

# 중복 개수 계산
partid_counter = Counter(partid_list)
for row in result_rows:
    partid = row[5]
    row.append(partid_counter[partid])  # `dup` 컬럼 추가

# 11월 4일부터 8일까지, 날짜별, 조별로 중복 개수가 1인 행 개수 집계
filtered_rows = [row for row in result_rows if row[6] >= '2024-11-04' and row[6] <= '2024-11-08' and row[9] == 1]
date_shift_counts = Counter((row[6], row[7]) for row in filtered_rows)

# 날짜와 조별로 개수 집계 결과 정리
dates = sorted(set(row[6] for row in filtered_rows))
shifts = ['day', 'night']
count_data = {date: [date_shift_counts.get((date, shift), 0) for shift in shifts] for date in dates}

# CSV 파일 저장 경로 설정
csv_file = 'c:\\agent\\splicing_logs.csv'
with open(csv_file, mode='w', newline='') as file:
    writer = csv.writer(file)
    writer.writerow(['line1', 'machine1', 'lane1', 'log1', 'log2', 'partid', 'date1', 'shift1', 'datatime1', 'dup'])
    writer.writerows(result_rows)

# 막대차트 시각화
fig, ax = plt.subplots(figsize=(10, 6))
bars = []
labels = []

for i, (date, counts) in enumerate(count_data.items()):
    for j, count in enumerate(counts):
        label = f"{date} ({shifts[j]})"
        bars.append(count)
        labels.append(label)

# 그래디언트 색상 적용
bars_plot = ax.bar(labels, bars, color=plt.cm.viridis([i / len(bars) for i in range(len(bars))]))

# 막대 위에 숫자 표시
for bar in bars_plot:
    height = bar.get_height()
    ax.text(bar.get_x() + bar.get_width() / 2, height, f'{int(height)}', ha='center', va='bottom')

# 차트 설정
ax.set_xlabel("날짜와 조")
ax.set_ylabel("중복이 1인 항목 개수")
ax.set_title("날짜별, 조별 중복이 1인 항목 개수")
plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

# 데이터베이스 연결 종료
conn.close()