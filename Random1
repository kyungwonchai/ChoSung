러닝 라이브러리에서 아직 지원되지 않을 수 있습니다. 따라서, Python 3.12에서도 잘 동작하는 PyTorch를 사용하여 딥러닝 모델을 추가한 학습 코드를 제공합니다.

수정된 코드: PyTorch 기반 딥러닝 모델 추가
주요 특징
PyTorch를 사용한 딥러닝 모델.
랜덤포레스트, XGBoost, 선형 회귀와 함께 평가.
최적 모델 선정 및 저장.
모든 모델의 평가 지표(MSE, RMSE, MAE) 시각화.
코드
python
코드 복사
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
import torch
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import joblib

# 데이터 가져오기 함수
def fetch_data_from_db(proc_name):
    """
    MSSQL 저장 프로시저에서 데이터를 가져옵니다.
    :param proc_name: 저장 프로시저 이름
    :return: pandas DataFrame
    """
    import pymssql
    server = "localhost"
    user = "your_username"
    password = "your_password"
    database = "your_database"
    try:
        conn = pymssql.connect(server=server, user=user, password=password, database=database)
        query = f"EXEC {proc_name}"
        df = pd.read_sql(query, conn)
        return df
    except Exception as e:
        print(f"Error fetching data: {e}")
        return pd.DataFrame()

# 데이터 준비
data = fetch_data_from_db("PRealAandB")
if data.empty:
    print("No data fetched. Exiting...")
    exit()

# 데이터 전처리
timestamps = data.iloc[:, 0]  # 시간 데이터 (첫 번째 열)
X = data.iloc[:, 2:5].values  # 특징 데이터 (3~5열)
y = data.iloc[:, 1].values    # 타겟 데이터 (2열)

# 학습 및 테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 사용할 모델 정의
models = {
    "LinearRegression": LinearRegression(),
    "RandomForest": RandomForestRegressor(n_estimators=100, random_state=42),
    "XGBoost": XGBRegressor(n_estimators=100, random_state=42)
}

# 평가지표 저장 딕셔너리
results = {
    "Model": [],
    "MSE": [],
    "RMSE": [],
    "MAE": [],
    "R2_Score": []
}

# 머신러닝 모델 학습 및 평가
print("Training and evaluating machine learning models...")
for model_name, model in models.items():
    print(f"Training {model_name}...")
    
    # 모델 학습
    model.fit(X_train, y_train)
    
    # 예측
    y_pred = model.predict(X_test)
    
    # 평가지표 계산
    mse = mean_squared_error(y_test, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    
    # 결과 저장
    results["Model"].append(model_name)
    results["MSE"].append(mse)
    results["RMSE"].append(rmse)
    results["MAE"].append(mae)
    results["R2_Score"].append(r2)
    
    print(f"{model_name}: MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R²={r2:.4f}")

# PyTorch 기반 딥러닝 모델 정의
class NeuralNetwork(nn.Module):
    def __init__(self):
        super(NeuralNetwork, self).__init__()
        self.fc1 = nn.Linear(X_train.shape[1], 16)  # 입력층 -> 은닉층1
        self.fc2 = nn.Linear(16, 8)                # 은닉층1 -> 은닉층2
        self.fc3 = nn.Linear(8, 1)                 # 은닉층2 -> 출력층

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x

# PyTorch 학습 함수
def train_pytorch_nn(X_train, y_train, X_test, y_test):
    model = NeuralNetwork()
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=0.01)
    
    # NumPy -> Tensor 변환
    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)
    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
    y_test_tensor = torch.tensor(y_test, dtype=torch.float32).view(-1, 1)
    
    # 학습
    for epoch in range(100):  # 100 epochs
        model.train()
        optimizer.zero_grad()
        outputs = model(X_train_tensor)
        loss = criterion(outputs, y_train_tensor)
        loss.backward()
        optimizer.step()
    
    # 평가
    model.eval()
    with torch.no_grad():
        predictions = model(X_test_tensor).numpy()
        mse = mean_squared_error(y_test, predictions)
        mae = mean_absolute_error(y_test, predictions)
    
    return model, mse, mae

# 딥러닝 모델 학습 및 평가
print("Training Neural Network...")
nn_model, nn_mse, nn_mae = train_pytorch_nn(X_train, y_train, X_test, y_test)
nn_rmse = np.sqrt(nn_mse)
results["Model"].append("NeuralNetwork")
results["MSE"].append(nn_mse)
results["RMSE"].append(nn_rmse)
results["MAE"].append(nn_mae)
results["R2_Score"].append(None)  # 딥러닝 모델에서 R² 계산 생략

# 결과 데이터프레임 생성
results_df = pd.DataFrame(results)

# 최적 모델 선택 (MSE 기준)
best_model_idx = results_df["MSE"].idxmin()
best_model_name = results_df.loc[best_model_idx, "Model"]
print(f"\nBest model: {best_model_name} with MSE={results_df.loc[best_model_idx, 'MSE']:.4f}")

# 최적 모델 저장
if best_model_name == "NeuralNetwork":
    torch.save(nn_model.state_dict(), "best_nn_model.pth")
    print("Neural Network model saved as 'best_nn_model.pth'")
else:
    best_model = models[best_model_name]
    joblib.dump(best_model, "best_model.pkl")
    print(f"{best_model_name} saved as 'best_model.pkl'")

# 시각화: 평가지표 비교
metrics = ["MSE", "RMSE", "MAE"]
fig, axes = plt.subplots(1, 3, figsize=(15, 5))

for i, metric in enumerate(metrics):
    axes[i].bar(results_df["Model"], results_df[metric], color=["blue", "orange", "green", "purple"])
    axes[i].set_title(f"Comparison of {metric}")
    axes[i].set_ylabel(metric)
    axes[i].grid(axis="y")

plt.tight_layout()
plt.show()
코드 설명
1. PyTorch 딥러닝 모델
NeuralNetwork 클래스:

2개의 은닉층과 1개의 출력층으로 구성된 단순한 신경망.
입력층 크기: 3 (3개의 특징).
출력층 크기: 1 (연속형 목표값).
학습:

손실 함수: MSELoss (Mean Squared Error).
최적화 알고리즘: Adam.
2. 모델 비교 및 최적 모델 저장
MSE, RMSE, MAE 기준으로 모델 성능을 비교.
최적 모델이 딥러닝일 경우 .pth 파일로 저장.
다른 모델은 .pkl 파일로 저장.
3. Python 3.12 지원
PyTorch는 Python 3.12에서 완벽히 동작합니다.